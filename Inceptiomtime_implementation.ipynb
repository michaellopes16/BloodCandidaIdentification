{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmVecdb9Dh-W"
      },
      "outputs": [],
      "source": [
        "#%pip install scikit-learn --upgrade --user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH5fdnNF8EIt"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTt1zjM_q92d",
        "outputId": "23c1e732-da02-4eef-cbd6-b9fa4402e79c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from builtins import print\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import random\n",
        "\n",
        "matplotlib.use('agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
        "matplotlib.rcParams['font.sans-serif'] = 'Arial'\n",
        "\n",
        "import os\n",
        "import operator\n",
        "#import utils\n",
        "\n",
        "#from utils.constants import UNIVARIATE_DATASET_NAMES as DATASET_NAMES\n",
        "#from utils.constants import UNIVARIATE_ARCHIVE_NAMES as ARCHIVE_NAMES\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "#from utils.utils import calculate_metrics\n",
        "#from utils.utils import create_directory\n",
        "#from utils.utils import check_if_file_exits\n",
        "import gc\n",
        "import time\n",
        "\n",
        "#from utils.utils import save_logs\n",
        "#from utils.utils import save_test_duration\n",
        "\n",
        "#from utils.utils import read_all_datasets\n",
        "#from utils.utils import transform_labels\n",
        "#from utils.utils import create_directory\n",
        "#from utils.utils import run_length_xps\n",
        "#from utils.utils import generate_results_csv\n",
        "\n",
        "import sys\n",
        "import sklearn\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhsrUO457K2C",
        "outputId": "d75268d5-13f7-4557-e9f5-42e4b0d63bcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AllCandidasBload_TEST.csv  AllCandidasBload_TRAIN.csv  AllCandidasBload_VAL.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/Colab Notebooks/Candidas/archives/TSC/AllCandidasBload/\")\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDDr_FbD_oIz",
        "outputId": "540813cc-790b-497e-8a82-f656e9cd9c0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.TextIOWrapper name='/content/drive/MyDrive/Colab Notebooks/Candidas/archives/TSC/AllCandidasBload/AllCandidasBload_TRAIN.csv' mode='r' encoding='UTF-8'>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "open(\"/content/drive/MyDrive/Colab Notebooks/Candidas/archives/TSC/AllCandidasBload/AllCandidasBload_TRAIN.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJc3qdwATvq3"
      },
      "outputs": [],
      "source": [
        "# SIZE_FILE = 652\n",
        "SIZE_FILE = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4z3uPGHKrXMC"
      },
      "outputs": [],
      "source": [
        "def check_if_file_exits(file_name):\n",
        "    return os.path.exists(file_name)\n",
        "\n",
        "\n",
        "def readucr(filename, delimiter=','):\n",
        "    print(filename)\n",
        "    data = pd.read_csv(filename, delimiter=delimiter,header=None)\n",
        "    Y = data.iloc[:, SIZE_FILE].values\n",
        "    X = data.iloc[:,0: SIZE_FILE].copy().values\n",
        "    return X, Y\n",
        "\n",
        "\n",
        "def readsits(filename, delimiter=','):\n",
        "    data = np.genfromtxt(filename, delimiter=delimiter)\n",
        "    Y = data[:, -1]\n",
        "    X = data[:, :-1]\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esRD1dQTrf1e"
      },
      "outputs": [],
      "source": [
        "def create_directory(directory_path):\n",
        "    if os.path.exists(directory_path):\n",
        "        return None\n",
        "    else:\n",
        "        try:\n",
        "            os.makedirs(directory_path)\n",
        "        except:\n",
        "            # in case another machine created the path meanwhile !:(\n",
        "            return None\n",
        "        return directory_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxzHJyO8rtmT"
      },
      "outputs": [],
      "source": [
        "def read_dataset(root_dir, archive_name, dataset_name):\n",
        "    datasets_dict = {}\n",
        "\n",
        "    file_name = root_dir + '/archives/' + archive_name + '/' + dataset_name + '/' + dataset_name\n",
        "    x_train, y_train = readucr(file_name + '_TRAIN.csv')\n",
        "    #Trocar aqui para teste depois\n",
        "    x_test, y_test = readucr(file_name + '_TEST.csv')\n",
        "    x_val, y_val = readucr(file_name + '_VAL.csv')\n",
        "    print(f\"x_train value:{x_train}\")\n",
        "    print(f\"y_train value:{y_train}\")\n",
        "    print(f\"x_test value:{x_test}\")\n",
        "    print(f\"y_test value:{y_test}\")\n",
        "    print(f\"x_val value:{x_val}\")\n",
        "    print(f\"y_val value:{y_val}\")\n",
        "\n",
        "    datasets_dict[dataset_name] = (x_train.copy(), y_train.copy(), x_test.copy(),\n",
        "                                   y_test.copy(), x_val.copy(),y_val.copy())\n",
        "\n",
        "    return datasets_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JB_-BQ2Sr1cg"
      },
      "outputs": [],
      "source": [
        "def read_all_datasets(root_dir, archive_name):\n",
        "    datasets_dict = {}\n",
        "\n",
        "    dataset_names_to_sort = []\n",
        "\n",
        "    if archive_name == 'TSC':\n",
        "        for dataset_name in UNIVARIATE_DATASET_NAMES:\n",
        "            root_dir_dataset = root_dir + '/archives/' + archive_name + '/' + dataset_name + '/'\n",
        "            file_name = root_dir_dataset + dataset_name\n",
        "            print(file_name)\n",
        "            x_train, y_train = readucr(file_name + '_TRAIN.csv')\n",
        "            #Trocar aqui para teste depois\n",
        "            x_test, y_test = readucr(file_name + '_TEST.csv')\n",
        "            x_val, y_val = readucr(file_name + '_VAL.csv')\n",
        "            print(f\"Valor do Xtrain no read_all_datasets {x_train}\")\n",
        "            print(f\"Valor do y_train no read_all_datasets {y_train}\")\n",
        "            datasets_dict[dataset_name] = (x_train.copy(), y_train.copy(), x_test.copy(),\n",
        "                                           y_test.copy(),x_val.copy(),y_val.copy())\n",
        "\n",
        "            dataset_names_to_sort.append((dataset_name, len(x_train)))\n",
        "\n",
        "        dataset_names_to_sort.sort(key=operator.itemgetter(1))\n",
        "\n",
        "        for i in range(len(UNIVARIATE_DATASET_NAMES)):\n",
        "            UNIVARIATE_DATASET_NAMES[i] = dataset_names_to_sort[i][0]\n",
        "    return datasets_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8E8is4aKNxBA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "def specificity_score(y_true, y_pred):\n",
        "    cm  = multilabel_confusion_matrix(y_true, y_pred)\n",
        "    specificity = []\n",
        "    for i in range(len(cm)):\n",
        "        tn = cm[i][0][0]\n",
        "        fp = cm[i][0][1]\n",
        "        spec = tn / (tn + fp)\n",
        "        specificity.append(spec)\n",
        "    avg_specificity = sum(specificity) / len(specificity)\n",
        "    return avg_specificity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9F82LTZsBen"
      },
      "outputs": [],
      "source": [
        "precision = []\n",
        "accuracy = []\n",
        "recall = []\n",
        "f1 = []\n",
        "specificity = []\n",
        "std = 0\n",
        "\n",
        "def calculate_metrics(y_test, y_pred, duration):\n",
        "    res = pd.DataFrame(data=np.zeros((1, 7), dtype=np.double), index=[0],\n",
        "                       columns=['precision', 'accuracy', 'recall','f1_score','duration','std','specificity'])\n",
        "    temp = precision_score(y_test, y_pred, average='macro')\n",
        "    print(f\"Temp: {temp}\")\n",
        "    res['precision'] = temp\n",
        "    res['accuracy'] = accuracy_score(y_test, y_pred)\n",
        "    res['recall'] = recall_score(y_test, y_pred, average='macro')\n",
        "    res['f1_score'] = f1_score(y_test, y_pred, average='macro')\n",
        "    res['specificity'] = specificity_score(y_test, y_pred)\n",
        "    res['duration'] = duration\n",
        "    print(res)\n",
        "    return res\n",
        "\n",
        "def calculate_metrics_per_class(y_val, y_pred, classes):\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    print(f\"Classes before: {classes}\")\n",
        "    classes = np.unique(classes)  # ou np.arange(n_classes) se souber o número de classes\n",
        "    print(f\"Classes after: {classes}\")\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    y_val = np.argmax(y_val, axis=1)\n",
        "    print(f\"Y_pred: {y_pred}\")\n",
        "    print(f\"y_val {y_val}\")\n",
        "    cm = confusion_matrix(y_val, y_pred, labels=classes)\n",
        "    metrics_per_class = []\n",
        "\n",
        "    for i, class_label in enumerate(classes):\n",
        "        TP = cm[i, i]\n",
        "        FN = cm[i, :].sum() - TP\n",
        "        FP = cm[:, i].sum() - TP\n",
        "        TN = cm.sum() - (TP + FP + FN)\n",
        "\n",
        "        accuracy = (TP + TN) / cm.sum() if cm.sum() > 0 else 0\n",
        "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        metrics_per_class.append({\n",
        "            'class': class_label,\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1,\n",
        "            'specificity': specificity\n",
        "        })\n",
        "\n",
        "    return metrics_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7T-lY3wZsBt5"
      },
      "outputs": [],
      "source": [
        "def save_test_duration(file_name, test_duration):\n",
        "    res = pd.DataFrame(data=np.zeros((1, 1), dtype=np.double), index=[0],\n",
        "                       columns=['test_duration'])\n",
        "    res['test_duration'] = test_duration\n",
        "    res.to_csv(file_name, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnUIJQ5ksB75"
      },
      "outputs": [],
      "source": [
        "def transform_labels(y_train, y_test, y_val):\n",
        "    \"\"\"\n",
        "    Transform label to min equal zero and continuous\n",
        "    For example if we have [1,3,4] --->  [0,1,2]\n",
        "    \"\"\"\n",
        "    # no validation split\n",
        "    # init the encoder\n",
        "    encoder = LabelEncoder()\n",
        "    # concat train and test to fit\n",
        "    y_train_test_val = np.concatenate((y_train, y_test, y_val), axis=0)\n",
        "    # fit the encoder\n",
        "    encoder.fit(y_train_test_val)\n",
        "    # transform to min zero and continuous labels\n",
        "    new_y_train_test = encoder.transform(y_train_test_val)\n",
        "    # resplit the train and test\n",
        "    new_y_train = new_y_train_test[0:len(y_train)]\n",
        "    new_y_test = new_y_train_test[len(y_train):len(y_train)+len(y_test)]\n",
        "    new_y_val = new_y_train_test[len(y_train)+len(y_test):]\n",
        "    return new_y_train, new_y_test, new_y_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApmmF3b0scMR"
      },
      "outputs": [],
      "source": [
        "def generate_results_csv(output_file_name, root_dir, clfs):\n",
        "    res = pd.DataFrame(data=np.zeros((0, 10), dtype=np.float64), index=[],\n",
        "                       columns=['classifier_name', 'archive_name', 'dataset_name', 'iteration',\n",
        "                                'precision', 'accuracy', 'recall','f1_score' ,'duration','std'])\n",
        "    for archive_name in UNIVARIATE_ARCHIVE_NAMES:\n",
        "        datasets_dict = read_all_datasets(root_dir, archive_name)\n",
        "        for classifier_name in clfs:\n",
        "            durr = 0.0\n",
        "\n",
        "            curr_archive_name = archive_name\n",
        "            for dataset_name in datasets_dict.keys():\n",
        "                output_dir = root_dir + '/results/' + classifier_name + '/' \\\n",
        "                             + curr_archive_name + '/' + dataset_name + '/' + 'df_metrics.csv'\n",
        "                #print(output_dir)\n",
        "                if not os.path.exists(output_dir):\n",
        "                    continue\n",
        "                df_metrics = pd.read_csv(output_dir)\n",
        "                df_metrics['classifier_name'] = classifier_name\n",
        "                df_metrics['archive_name'] = archive_name\n",
        "                df_metrics['dataset_name'] = dataset_name\n",
        "                df_metrics['iteration'] = 0\n",
        "                res = pd.concat((res, df_metrics), axis=0, sort=False)\n",
        "                durr += df_metrics['duration'][0]\n",
        "\n",
        "    res.to_csv(root_dir + output_file_name, index=False)\n",
        "\n",
        "    res = res.loc[res['classifier_name'].isin(clfs)]\n",
        "\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYAf8aF9scW0"
      },
      "outputs": [],
      "source": [
        "def plot_epochs_metric(hist, file_name, metric='loss'):\n",
        "    plt.figure()\n",
        "    plt.plot(hist.history[metric])\n",
        "    plt.plot(hist.history['val_' + metric])\n",
        "    plt.title('model ' + metric)\n",
        "    plt.ylabel(metric, fontsize='large')\n",
        "    plt.xlabel('epoch', fontsize='large')\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "    plt.savefig(file_name, bbox_inches='tight')\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CyqisiEscgC"
      },
      "outputs": [],
      "source": [
        "def save_logs(output_directory, hist, y_pred, y_test, duration,\n",
        "              lr=True, plot_test_acc=True):\n",
        "    hist_df = pd.DataFrame(hist.history)\n",
        "    #2 * (Precision * Recall) / (Precision + Recall)\n",
        "    print(\"Histórico\")\n",
        "    print(hist_df)\n",
        "    hist_df['f1'] = 2 * ((hist_df.iloc[:, 3] * hist_df.iloc[:, 2])/(hist_df.iloc[:, 3] + hist_df.iloc[:, 2]))\n",
        "    hist_df.to_csv(output_directory + 'history.csv', index=False)\n",
        "\n",
        "    df_metrics = calculate_metrics(y_test, y_pred, duration)\n",
        "    precision.append(df_metrics['precision'])\n",
        "    specificity.append(df_metrics['specificity'])\n",
        "    accuracy.append(df_metrics['accuracy'])\n",
        "    recall.append(df_metrics['recall'])\n",
        "    f1.append(df_metrics['f1_score'])\n",
        "\n",
        "    df_metrics.to_csv(output_directory + 'df_metrics_val.csv', index=False)\n",
        "\n",
        "    index_best_model = hist_df['loss'].idxmin()\n",
        "    row_best_model = hist_df.loc[index_best_model]\n",
        "\n",
        "    df_best_model = pd.DataFrame(data=np.zeros((1, 6), dtype=np.float64), index=[0],\n",
        "                                 columns=['best_model_train_loss', 'best_model_val_loss', 'best_model_train_acc',\n",
        "                                          'best_model_val_acc', 'best_model_learning_rate', 'best_model_nb_epoch'])\n",
        "\n",
        "    df_best_model['best_model_train_loss'] = row_best_model['loss']\n",
        "    #if plot_test_acc:\n",
        "    #    df_best_model['best_model_val_loss'] = row_best_model['val_loss']\n",
        "    #df_best_model['best_model_train_acc'] = row_best_model['acc']\n",
        "    if plot_test_acc:\n",
        "        df_best_model['best_model_val_acc'] = row_best_model['val_acc']\n",
        "    if lr == True:\n",
        "        df_best_model['best_model_learning_rate'] = row_best_model['lr']\n",
        "    df_best_model['best_model_nb_epoch'] = index_best_model\n",
        "\n",
        "    df_best_model.to_csv(output_directory + 'df_best_model.csv', index=False)\n",
        "\n",
        "    if plot_test_acc:\n",
        "        # plot losses\n",
        "        plot_epochs_metric(hist, output_directory + 'epochs_loss.png')\n",
        "\n",
        "    return df_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9uNdVgzs1mo"
      },
      "outputs": [],
      "source": [
        "def create_synthetic_dataset(pattern_len=[0.25], pattern_pos=[0.1, 0.65], ts_len=128, ts_n=128):\n",
        "    random.seed(1234)\n",
        "    np.random.seed(1234)\n",
        "\n",
        "    nb_classes = len(pattern_pos) * len(pattern_len)\n",
        "\n",
        "    out_dir = '/b/home/uha/hfawaz-datas/dl-tsc/archives/UCRArchive_2018/BinaryData/'\n",
        "\n",
        "    create_directory(out_dir)\n",
        "\n",
        "    x_train = np.random.normal(0.0, 0.1, size=(ts_n, ts_len))\n",
        "    x_test = np.random.normal(0.0, 0.1, size=(ts_n, ts_len))\n",
        "\n",
        "    y_train = np.random.randint(low=0, high=nb_classes, size=(ts_n,))\n",
        "    y_test = np.random.randint(low=0, high=nb_classes, size=(ts_n,))\n",
        "\n",
        "    # make sure at least each class has one example\n",
        "    y_train[:nb_classes] = np.arange(start=0, stop=nb_classes, dtype=np.int32)\n",
        "    y_test[:nb_classes] = np.arange(start=0, stop=nb_classes, dtype=np.int32)\n",
        "\n",
        "    # each class is defined with a certain combination of pattern_pos and pattern_len\n",
        "    # with one pattern_len and two pattern_pos we can create only two classes\n",
        "    # example:  class 0 _____-_  & class 1 _-_____\n",
        "\n",
        "    # create the class definitions\n",
        "    class_def = [None for i in range(nb_classes)]\n",
        "\n",
        "    idx_class = 0\n",
        "    for pl in pattern_len:\n",
        "        for pp in pattern_pos:\n",
        "            class_def[idx_class] = {'pattern_len': int(pl * ts_len),\n",
        "                                    'pattern_pos': int(pp * ts_len)}\n",
        "            idx_class += 1\n",
        "\n",
        "    # create the dataset\n",
        "    for i in range(ts_n):\n",
        "        # for the train\n",
        "        c = y_train[i]\n",
        "        curr_pattern_pos = class_def[c]['pattern_pos']\n",
        "        curr_pattern_len = class_def[c]['pattern_len']\n",
        "        x_train[i][curr_pattern_pos:curr_pattern_pos + curr_pattern_len] = \\\n",
        "            x_train[i][curr_pattern_pos:curr_pattern_pos + curr_pattern_len] + 1.0\n",
        "\n",
        "        # for the test\n",
        "        c = y_test[i]\n",
        "        curr_pattern_pos = class_def[c]['pattern_pos']\n",
        "        curr_pattern_len = class_def[c]['pattern_len']\n",
        "        x_test[i][curr_pattern_pos:curr_pattern_pos + curr_pattern_len] = \\\n",
        "            x_test[i][curr_pattern_pos:curr_pattern_pos + curr_pattern_len] + 1.0\n",
        "\n",
        "    # znorm\n",
        "    x_train = (x_train - x_train.mean(axis=1, keepdims=True)) \\\n",
        "              / x_train.std(axis=1, keepdims=True)\n",
        "\n",
        "    x_test = (x_test - x_test.mean(axis=1, keepdims=True)) \\\n",
        "             / x_test.std(axis=1, keepdims=True)\n",
        "\n",
        "    # visualize example\n",
        "    # plt.figure()\n",
        "    # colors = generate_array_of_colors(nb_classes)\n",
        "    # for c in range(nb_classes):\n",
        "    #     plt.plot(x_train[y_train == c][0], color=colors[c], label='class-' + str(c))\n",
        "    # plt.legend(loc='best')\n",
        "    # plt.savefig('out.pdf')\n",
        "    # exit()\n",
        "\n",
        "    # np.save(out_dir+'x_train.npy',x_train)\n",
        "    # np.save(out_dir+'y_train.npy',y_train)\n",
        "    # np.save(out_dir+'x_test.npy',x_test)\n",
        "    # np.save(out_dir+'y_test.npy',y_test)\n",
        "\n",
        "    # print('Done creating dataset!')\n",
        "\n",
        "    return x_train, y_train, x_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPgcX9m4s1sK"
      },
      "outputs": [],
      "source": [
        "def generate_array_of_colors(n):\n",
        "    # https://www.quora.com/How-do-I-generate-n-visually-distinct-RGB-colours-in-Python\n",
        "    ret = []\n",
        "    r = int(random.random() * 256)\n",
        "    g = int(random.random() * 256)\n",
        "    b = int(random.random() * 256)\n",
        "    alpha = 1.0\n",
        "    step = 256 / n\n",
        "    for i in range(n):\n",
        "        r += step\n",
        "        g += step\n",
        "        b += step\n",
        "        r = int(r) % 256\n",
        "        g = int(g) % 256\n",
        "        b = int(b) % 256\n",
        "        ret.append((r / 255, g / 255, b / 255, alpha))\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WRYP7qfs1x4"
      },
      "outputs": [],
      "source": [
        "# def read_sits_xps(root_dir):\n",
        "#     datasets_dict = {}\n",
        "#     path_to_data = root_dir + 'archives/SITS/resampled-SITS/'\n",
        "#     path_to_test = root_dir + 'archives/SITS/' + 'SatelliteFull_TEST_1000.csv'\n",
        "\n",
        "#     x_test, y_test = readsits(path_to_test)\n",
        "\n",
        "#     for subdir, dirs, files in os.walk(path_to_data):\n",
        "#         for file_name in files:\n",
        "#             arr = file_name.split('.')\n",
        "#             dataset_name = arr[0]\n",
        "#             file_type = arr[1]\n",
        "#             if file_type == 'csv':\n",
        "#                 x_train, y_train = readsits(subdir + '/' + file_name)\n",
        "\n",
        "#                 datasets_dict[dataset_name] = (x_train.copy(), y_train.copy(), x_test.copy(),\n",
        "#                                                y_test.copy())\n",
        "\n",
        "#     return datasets_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckLDgRLzs17H"
      },
      "outputs": [],
      "source": [
        "def resample_dataset(x, rate):\n",
        "    new_x = np.zeros(shape=(x.shape[0], rate))\n",
        "    from scipy import signal\n",
        "    for i in range(x.shape[0]):\n",
        "        f = signal.resample(x[0], rate)\n",
        "        new_x[i] = f\n",
        "    return new_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GApt7T0MtRF2"
      },
      "outputs": [],
      "source": [
        "def run_length_xps(root_dir):\n",
        "    #archive_name = ARCHIVE_NAMES[0]\n",
        "    archive_name = UNIVARIATE_ARCHIVE_NAMES[0]\n",
        "    dataset_name = 'InlineSkate'\n",
        "    datasets_dict = read_dataset(root_dir, archive_name, dataset_name)\n",
        "\n",
        "    lengths = [2 ** i for i in range(5, 12)]\n",
        "\n",
        "    x_train = datasets_dict[dataset_name][0]\n",
        "    y_train = datasets_dict[dataset_name][1]\n",
        "    x_test = datasets_dict[dataset_name][2]\n",
        "    y_test = datasets_dict[dataset_name][3]\n",
        "    x_val = datasets_dict[dataset_name][4]\n",
        "    y_val = datasets_dict[dataset_name][5]\n",
        "\n",
        "    new_archive_name = 'TSC'\n",
        "#    new_archive_name = 'InlineSkateXPs'\n",
        "\n",
        "    for l in lengths:\n",
        "        new_x_train = resample_dataset(x_train, l)\n",
        "        new_x_test = resample_dataset(x_test, l)\n",
        "        new_x_val = resample_dataset(x_val, l)\n",
        "        new_dataset_name = dataset_name + '-' + str(l)\n",
        "        new_dataset_dir = root_dir + 'archives/' + new_archive_name + '/' + new_dataset_name + '/'\n",
        "        create_directory(new_dataset_dir)\n",
        "\n",
        "        np.save(new_dataset_dir + 'x_train.npy', new_x_train)\n",
        "        np.save(new_dataset_dir + 'y_train.npy', y_train)\n",
        "        np.save(new_dataset_dir + 'x_test.npy', new_x_test)\n",
        "        np.save(new_dataset_dir + 'y_test.npy', y_test)\n",
        "        np.save(new_dataset_dir + 'x_val.npy', new_x_val)\n",
        "        np.save(new_dataset_dir + 'y_val.npy', y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1yznVGrtRT4"
      },
      "outputs": [],
      "source": [
        "UNIVARIATE_DATASET_NAMES = ['AllCandidasBload']\n",
        "\n",
        "UNIVARIATE_ARCHIVE_NAMES = ['TSC', 'InlineSkateXPs', 'SITS']\n",
        "\n",
        "SITS_DATASETS = ['SatelliteFull_TRAIN_c301', 'SatelliteFull_TRAIN_c200', 'SatelliteFull_TRAIN_c451',\n",
        "                 'SatelliteFull_TRAIN_c89', 'SatelliteFull_TRAIN_c677', 'SatelliteFull_TRAIN_c59',\n",
        "                 'SatelliteFull_TRAIN_c133']\n",
        "\n",
        "InlineSkateXPs_DATASETS = ['InlineSkate-32', 'InlineSkate-64', 'InlineSkate-128',\n",
        "                           'InlineSkate-256', 'InlineSkate-512', 'InlineSkate-1024',\n",
        "                           'InlineSkate-2048']\n",
        "\n",
        "dataset_names_for_archive = {'TSC': UNIVARIATE_DATASET_NAMES,\n",
        "                             'SITS': SITS_DATASETS,\n",
        "                             'InlineSkateXPs': InlineSkateXPs_DATASETS}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLqd9yE9q0cw"
      },
      "outputs": [],
      "source": [
        "class Classifier_NNE:\n",
        "\n",
        "    def create_classifier(self, model_name, input_shape, nb_classes, output_directory, verbose=False,\n",
        "                          build=True):\n",
        "        if self.check_if_match('inception*', model_name):\n",
        "            #from classifiers import inception\n",
        "            return Classifier_INCEPTION(output_directory, input_shape, nb_classes, verbose, build=build)\n",
        "\n",
        "    def check_if_match(self, rex, name2):\n",
        "        import re\n",
        "        pattern = re.compile(rex)\n",
        "        return pattern.match(name2)\n",
        "\n",
        "    def __init__(self, output_directory, input_shape, nb_classes, verbose=False, nb_iterations=5,\n",
        "                 clf_name='inception'):\n",
        "        self.classifiers = [clf_name]\n",
        "        out_add = ''\n",
        "        for cc in self.classifiers:\n",
        "            out_add = out_add + cc + '-'\n",
        "        self.archive_name = UNIVARIATE_ARCHIVE_NAMES[0]\n",
        "        self.iterations_to_take = [i for i in range(nb_iterations)]\n",
        "        for cc in self.iterations_to_take:\n",
        "            out_add = out_add + str(cc) + '-'\n",
        "        self.output_directory = output_directory.replace('nne',\n",
        "                                                         'nne' + '/' + out_add)\n",
        "        create_directory(self.output_directory)\n",
        "        self.dataset_name = output_directory.split('/')[-2]\n",
        "        self.verbose = verbose\n",
        "        self.models_dir = output_directory.replace('nne', 'classifier')\n",
        "\n",
        "    def fit(self, x_train, y_train, x_test, y_test, y_true):\n",
        "        # no training since models are pre-trained\n",
        "        start_time = time.time()\n",
        "\n",
        "        y_pred = np.zeros(shape=y_test.shape)\n",
        "\n",
        "        ll = 0\n",
        "\n",
        "        # loop through all classifiers\n",
        "        for model_name in self.classifiers:\n",
        "            # loop through different initialization of classifiers\n",
        "            for itr in self.iterations_to_take:\n",
        "                if itr == 0:\n",
        "                    itr_str = ''\n",
        "                else:\n",
        "                    itr_str = '_itr_' + str(itr)\n",
        "\n",
        "                curr_archive_name = self.archive_name + itr_str\n",
        "\n",
        "                curr_dir = self.models_dir.replace('classifier', model_name).replace(\n",
        "                    self.archive_name, curr_archive_name)\n",
        "\n",
        "                model = self.create_classifier(model_name, None, None,\n",
        "                                               curr_dir, build=False)\n",
        "\n",
        "                predictions_file_name = curr_dir + 'y_pred.npy'\n",
        "                # check if predictions already made\n",
        "                if check_if_file_exits(predictions_file_name):\n",
        "                    # then load only the predictions from the file\n",
        "                    curr_y_pred = np.load(predictions_file_name)\n",
        "                else:\n",
        "                    # then compute the predictions\n",
        "                    curr_y_pred = model.predict(x_test, y_true, x_train, y_train, y_test,\n",
        "                                                return_df_metrics=False)\n",
        "                    keras.backend.clear_session()\n",
        "\n",
        "                    np.save(predictions_file_name, curr_y_pred)\n",
        "\n",
        "                y_pred = y_pred + curr_y_pred\n",
        "\n",
        "                ll += 1\n",
        "\n",
        "        # average predictions\n",
        "        y_pred = y_pred / ll\n",
        "\n",
        "        # save predictions\n",
        "        np.save(self.output_directory + 'y_pred.npy', y_pred)\n",
        "\n",
        "        # convert the predicted from binary to integer\n",
        "        y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "        duration = time.time() - start_time\n",
        "\n",
        "        df_metrics = calculate_metrics(y_test, y_pred, duration)\n",
        "\n",
        "        df_metrics.to_csv(self.output_directory + 'df_metrics_val.csv', index=False)\n",
        "\n",
        "        gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdNdNnM4tSUq"
      },
      "outputs": [],
      "source": [
        "class Classifier_INCEPTION:\n",
        "\n",
        "    def __init__(self, output_directory, input_shape, nb_classes, iter, verbose=False, inverbose=False, build=True, batch_size=64,\n",
        "                 nb_filters=32, use_residual=True, use_bottleneck=True, depth=6, kernel_size=41, nb_epochs=1500):\n",
        "\n",
        "        self.output_directory = output_directory\n",
        "\n",
        "        self.nb_filters = nb_filters\n",
        "        self.use_residual = use_residual\n",
        "        self.use_bottleneck = use_bottleneck\n",
        "        self.depth = depth\n",
        "        self.kernel_size = kernel_size - 1\n",
        "        self.callbacks = None\n",
        "        self.batch_size = batch_size\n",
        "        self.bottleneck_size = 32\n",
        "        self.nb_epochs = nb_epochs\n",
        "        self.all_class_metrics = []\n",
        "        self.iter = iter\n",
        "\n",
        "\n",
        "        if build == True:\n",
        "            self.model = self.build_model(input_shape, nb_classes)\n",
        "            if (verbose == True):\n",
        "                self.model.summary()\n",
        "            self.verbose = verbose\n",
        "            self.model.save_weights(self.output_directory + 'model_init.weights.h5')\n",
        "\n",
        "    def _inception_module(self, input_tensor, stride=1, activation='linear'):\n",
        "\n",
        "        if self.use_bottleneck and int(input_tensor.shape[-1]) > 1:\n",
        "            input_inception = keras.layers.Conv1D(filters=self.bottleneck_size, kernel_size=1,\n",
        "                                                  padding='same', activation=activation, use_bias=False)(input_tensor)\n",
        "        else:\n",
        "            input_inception = input_tensor\n",
        "\n",
        "        # kernel_size_s = [3, 5, 8, 11, 17]\n",
        "        kernel_size_s = [self.kernel_size // (2 ** i) for i in range(3)]\n",
        "\n",
        "        conv_list = []\n",
        "\n",
        "        for i in range(len(kernel_size_s)):\n",
        "            conv_list.append(keras.layers.Conv1D(filters=self.nb_filters, kernel_size=kernel_size_s[i],\n",
        "                                                 strides=stride, padding='same', activation=activation, use_bias=False)(\n",
        "                input_inception))\n",
        "\n",
        "        max_pool_1 = keras.layers.MaxPool1D(pool_size=3, strides=stride, padding='same')(input_tensor)\n",
        "\n",
        "        conv_6 = keras.layers.Conv1D(filters=self.nb_filters, kernel_size=1,\n",
        "                                     padding='same', activation=activation, use_bias=False)(max_pool_1)\n",
        "\n",
        "        conv_list.append(conv_6)\n",
        "\n",
        "        x = keras.layers.Concatenate(axis=2)(conv_list)\n",
        "        x = keras.layers.BatchNormalization()(x)\n",
        "        x = keras.layers.Activation(activation='relu')(x)\n",
        "        return x\n",
        "\n",
        "    def _shortcut_layer(self, input_tensor, out_tensor):\n",
        "        shortcut_y = keras.layers.Conv1D(filters=int(out_tensor.shape[-1]), kernel_size=1,\n",
        "                                         padding='same', use_bias=False)(input_tensor)\n",
        "        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
        "\n",
        "        x = keras.layers.Add()([shortcut_y, out_tensor])\n",
        "        x = keras.layers.Activation('relu')(x)\n",
        "        return x\n",
        "\n",
        "    def build_model(self, input_shape, nb_classes):\n",
        "        input_layer = keras.layers.Input(input_shape)\n",
        "\n",
        "        x = input_layer\n",
        "        input_res = input_layer\n",
        "\n",
        "        for d in range(self.depth):\n",
        "\n",
        "            x = self._inception_module(x)\n",
        "\n",
        "            if self.use_residual and d % 3 == 2:\n",
        "                x = self._shortcut_layer(input_res, x)\n",
        "                input_res = x\n",
        "\n",
        "        gap_layer = keras.layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "        output_layer = keras.layers.Dense(nb_classes, activation='softmax')(gap_layer)\n",
        "\n",
        "        model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(),\n",
        "                      metrics= [\n",
        "                                tf.keras.metrics.CategoricalAccuracy(name='accuracy', dtype=None),\n",
        "                                tf.keras.metrics.Recall(),\n",
        "                                tf.keras.metrics.Precision(),\n",
        "                                tf.keras.metrics.TruePositives(),\n",
        "                                tf.keras.metrics.TrueNegatives(),\n",
        "                                tf.keras.metrics.FalsePositives(),\n",
        "                                tf.keras.metrics.FalseNegatives()\n",
        "                                ])\n",
        "\n",
        "        reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50,\n",
        "                                                      min_lr=0.0001)\n",
        "\n",
        "        file_path = self.output_directory + 'best_model.keras'\n",
        "\n",
        "        model_checkpoint = keras.callbacks.ModelCheckpoint(filepath=file_path, monitor='loss',\n",
        "                                                           save_best_only=True)\n",
        "\n",
        "        self.callbacks = [reduce_lr, model_checkpoint]\n",
        "\n",
        "        return model\n",
        "\n",
        "    def fit(self, x_train, y_train, x_val, y_val, y_true, plot_test_acc=False):\n",
        "        #if len(keras.backend.tensorflow_backend._get_available_gpus()) == 0:\n",
        "        #    print('error no gpu')\n",
        "        #    exit()\n",
        "        # x_val and y_val are only used to monitor the test loss and NOT for training\n",
        "        print(\"Dentro do FitModel\")\n",
        "        if self.batch_size is None:\n",
        "            mini_batch_size = int(min(x_train.shape[0] / 10, 16))\n",
        "        else:\n",
        "            mini_batch_size = self.batch_size\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        if plot_test_acc:\n",
        "\n",
        "            hist = self.model.fit(x_train, y_train, batch_size=mini_batch_size, epochs=self.nb_epochs,\n",
        "                                  verbose=self.verbose, validation_data=(x_val, y_val), callbacks=self.callbacks)\n",
        "        else:\n",
        "\n",
        "            hist = self.model.fit(x_train, y_train, batch_size=mini_batch_size, epochs=self.nb_epochs,\n",
        "                                  verbose=self.verbose, callbacks=self.callbacks)\n",
        "\n",
        "        duration = time.time() - start_time\n",
        "\n",
        "        self.model.save(self.output_directory + 'last_model.hdf5')\n",
        "\n",
        "        y_pred = self.predict(x_val, y_true, x_train, y_train, y_val,\n",
        "                              return_df_metrics=False)\n",
        "\n",
        "        # save predictions\n",
        "        np.save(self.output_directory + 'y_pred.npy', y_pred)\n",
        "         # save predictions\n",
        "        np.save(self.output_directory + 'y_true.npy', y_true)\n",
        "\n",
        "        # convert the predicted from binary to integer\n",
        "        print(f\"y_pred before save =  \\n {y_pred}\")\n",
        "        y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "        df_metrics = save_logs(self.output_directory, hist, y_pred, y_true, duration,\n",
        "                               plot_test_acc=plot_test_acc, lr=False)\n",
        "\n",
        "        keras.backend.clear_session()\n",
        "\n",
        "        return df_metrics\n",
        "\n",
        "    def predict(self, x_test, y_true, x_train, y_train, y_test, return_df_metrics=True):\n",
        "        start_time = time.time()\n",
        "        model_path = self.output_directory + 'best_model.keras'\n",
        "        model = keras.models.load_model(model_path)\n",
        "        y_pred = model.predict(x_test, batch_size=self.batch_size)\n",
        "        test_duration = time.time() - start_time\n",
        "        save_test_duration(self.output_directory + 'test_duration.csv', test_duration)\n",
        "\n",
        "        classes = np.argmax(y_train, axis=1)\n",
        "        class_metrics = calculate_metrics_per_class(y_test, y_pred, classes)\n",
        "        for metrics in class_metrics:\n",
        "            metrics.update({'model': \"IncepionTime\", 'fold': self.iter})\n",
        "            self.all_class_metrics.append(metrics)\n",
        "        df = pd.DataFrame(self.all_class_metrics)\n",
        "        df.to_csv(self.output_directory + \"all_class_metrics.csv\", index=False)\n",
        "\n",
        "        if return_df_metrics:\n",
        "            y_pred = np.argmax(y_pred, axis=1)\n",
        "            df_metrics = calculate_metrics(y_test, y_pred, 0.0)\n",
        "            return df_metrics\n",
        "        else:\n",
        "            return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80oEFjNvtR-C"
      },
      "outputs": [],
      "source": [
        "def prepare_data():\n",
        "    x_train = datasets_dict[dataset_name][0]\n",
        "    y_train = datasets_dict[dataset_name][1]\n",
        "    x_test = datasets_dict[dataset_name][2]\n",
        "    y_test = datasets_dict[dataset_name][3]\n",
        "    x_val = datasets_dict[dataset_name][4]\n",
        "    y_val = datasets_dict[dataset_name][5]\n",
        "    print(f\"valor de x_train no prepare data {x_train}\")\n",
        "    print(f\"valor de y_train no prepare data {y_train}\")\n",
        "    print(f\"valor de y_val no prepare data {y_val}\")\n",
        "    nb_classes = len(np.unique(np.concatenate((y_train, y_test,y_val ), axis=0)))\n",
        "\n",
        "    # make the min to zero of labels\n",
        "    y_train, y_test, y_val = transform_labels(y_train, y_test, y_val)\n",
        "\n",
        "    # save orignal y because later we will use binary\n",
        "    y_true = y_test.astype(np.int64)\n",
        "    y_true_train = y_train.astype(np.int64)\n",
        "    y_true_val = y_val.astype(np.int64)\n",
        "    # transform the labels from integers to one hot vectors\n",
        "    enc = sklearn.preprocessing.OneHotEncoder()\n",
        "    enc.fit(np.concatenate((y_train, y_test,y_val), axis=0).reshape(-1, 1))\n",
        "    y_train = enc.transform(y_train.reshape(-1, 1)).toarray()\n",
        "    y_test = enc.transform(y_test.reshape(-1, 1)).toarray()\n",
        "    y_val = enc.transform(y_val.reshape(-1, 1)).toarray()\n",
        "\n",
        "    if len(x_train.shape) == 2:  # if univariate\n",
        "        # add a dimension to make it multivariate with one dimension\n",
        "        x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "        x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
        "        x_val = x_val.reshape((x_val.shape[0], x_val.shape[1], 1))\n",
        "\n",
        "    return x_train, y_train, x_test, y_test, x_test, x_val, y_val, y_true, nb_classes, y_true_train, enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyhMePQgyywk"
      },
      "outputs": [],
      "source": [
        "def fit_classifier(iter):\n",
        "    input_shape = x_train.shape[1:]\n",
        "\n",
        "    classifier = create_classifier(classifier_name, input_shape, nb_classes,\n",
        "                                   output_directory, iter)\n",
        "\n",
        "    classifier.fit(x_train, y_train, x_test, y_test, y_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_qBGd3dzDjg"
      },
      "outputs": [],
      "source": [
        "def create_classifier(classifier_name, input_shape, nb_classes, output_directory, iter,\n",
        "                      verbose=False, build=True):\n",
        "    if classifier_name == 'nne':\n",
        "        #from classifiers import nne\n",
        "        return Classifier_NNE(output_directory, input_shape, nb_classes, verbose)\n",
        "\n",
        "    if classifier_name == 'inception':\n",
        "        #from classifiers import inception\n",
        "        return Classifier_INCEPTION(output_directory, input_shape, nb_classes, iter,\n",
        "                                    verbose, build=build)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nbk-HPHpzDw3"
      },
      "outputs": [],
      "source": [
        "def get_xp_val(xp):\n",
        "    if xp == 'batch_size':\n",
        "        xp_arr = [16, 32, 128]\n",
        "    elif xp == 'use_bottleneck':\n",
        "        xp_arr = [False]\n",
        "    elif xp == 'use_residual':\n",
        "        xp_arr = [False]\n",
        "    elif xp == 'nb_filters':\n",
        "        xp_arr = [16, 64]\n",
        "    elif xp == 'depth':\n",
        "        xp_arr = [3, 9]\n",
        "    elif xp == 'kernel_size':\n",
        "        xp_arr = [8, 64]\n",
        "    else:\n",
        "        raise Exception('wrong argument')\n",
        "    return xp_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKy73uyc_smT"
      },
      "outputs": [],
      "source": [
        "############################################### main\n",
        "\n",
        "#root_dir = '/b/home/uha/hfawaz-datas/temp-dl-tsc/'\n",
        "\n",
        "root_dir = '/content/drive/MyDrive/Colab Notebooks/Candidas'\n",
        "\n",
        "xps = ['use_bottleneck', 'use_residual', 'nb_filters', 'depth',\n",
        "       'kernel_size', 'batch_size']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2cjLDVFJchw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-YSk5I-JbdP"
      },
      "outputs": [],
      "source": [
        "# device_name = tf.test.gpu_device_name()\n",
        "# if device_name != '/device:GPU:0':\n",
        "#   raise SystemError('GPU device not found')\n",
        "# print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-VpDwoYJk38"
      },
      "outputs": [],
      "source": [
        "# device_name = tf.test.gpu_device_name()\n",
        "# if device_name != '/device:GPU:0':\n",
        "#   print(\n",
        "#       '\\n\\nThis error most likely means that this notebook is not '\n",
        "#       'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "#       'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "#   raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c78wadTW_uJ6",
        "outputId": "dfe3c201-ecb1-48b4-e9c4-92556b66769e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Candidas/archives/TSC/AllCandidasBload/AllCandidasBload\n",
            "/content/drive/MyDrive/Colab Notebooks/Candidas/archives/TSC/AllCandidasBload/AllCandidasBload_TRAIN.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/Candidas/archives/TSC/AllCandidasBload/AllCandidasBload_TEST.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/Candidas/archives/TSC/AllCandidasBload/AllCandidasBload_VAL.csv\n",
            "Valor do Xtrain no read_all_datasets [[1295.   843.3 1091.  ...  846.4 1120.   497.5]\n",
            " [1486.   983.3 1471.  ...  984.7 1659.   578.5]\n",
            " [1374.   927.9  561.3 ...  915.  1371.   559.5]\n",
            " ...\n",
            " [1255.   813.1 1096.  ...  815.5 1091.   472.9]\n",
            " [1571.  1023.  1555.  ... 1027.  1561.   626.2]\n",
            " [1551.  1053.  1329.  ... 1060.  1319.   621.6]]\n",
            "Valor do y_train no read_all_datasets [5. 2. 6. 1. 4. 6. 1. 6. 2. 5. 1. 6. 1. 5. 1. 1. 6. 4. 5. 6. 6. 6. 5. 4.\n",
            " 2. 3. 5. 5. 1. 2. 6. 6. 2. 1. 5. 6. 4. 4. 2. 5. 5. 4. 6. 6. 4. 6. 2. 5.\n",
            " 6. 2. 1. 6. 6. 5. 2. 6. 5. 1. 5. 5. 6. 4. 5. 4. 5. 1. 5. 2. 4. 2. 5. 5.\n",
            " 2. 2. 4. 5. 2. 5. 2. 1. 4. 6. 2. 6. 5. 3. 4. 6. 2. 1. 2. 1. 6. 4. 6. 6.\n",
            " 6. 2. 5. 2. 2. 2. 1. 2. 2. 1. 3. 6. 6. 1. 2. 5. 5. 6. 5. 2. 5. 5. 6. 6.\n",
            " 1. 4. 2. 2. 6. 1. 1. 6. 1. 1. 6. 2. 6. 6. 2. 4. 2. 6. 1. 1. 5. 5. 5. 6.\n",
            " 1. 5. 2. 1. 1. 2. 5. 2. 2. 2. 6. 3. 2. 2. 6. 6. 5. 5. 5. 1. 6. 2. 5. 4.\n",
            " 3. 6. 6. 5. 5. 4. 6. 1. 2. 6. 4. 6. 4. 2. 1. 6. 2. 4. 6. 3. 2. 2. 5. 4.\n",
            " 1. 6. 6. 3. 1. 1. 2. 1. 2. 5. 2. 4.]\n",
            "\t\titer 0\n",
            "\t\t\tdataset_name:  AllCandidasBload\n",
            "valor de x_train no prepare data [[1295.   843.3 1091.  ...  846.4 1120.   497.5]\n",
            " [1486.   983.3 1471.  ...  984.7 1659.   578.5]\n",
            " [1374.   927.9  561.3 ...  915.  1371.   559.5]\n",
            " ...\n",
            " [1255.   813.1 1096.  ...  815.5 1091.   472.9]\n",
            " [1571.  1023.  1555.  ... 1027.  1561.   626.2]\n",
            " [1551.  1053.  1329.  ... 1060.  1319.   621.6]]\n",
            "valor de y_train no prepare data [5. 2. 6. 1. 4. 6. 1. 6. 2. 5. 1. 6. 1. 5. 1. 1. 6. 4. 5. 6. 6. 6. 5. 4.\n",
            " 2. 3. 5. 5. 1. 2. 6. 6. 2. 1. 5. 6. 4. 4. 2. 5. 5. 4. 6. 6. 4. 6. 2. 5.\n",
            " 6. 2. 1. 6. 6. 5. 2. 6. 5. 1. 5. 5. 6. 4. 5. 4. 5. 1. 5. 2. 4. 2. 5. 5.\n",
            " 2. 2. 4. 5. 2. 5. 2. 1. 4. 6. 2. 6. 5. 3. 4. 6. 2. 1. 2. 1. 6. 4. 6. 6.\n",
            " 6. 2. 5. 2. 2. 2. 1. 2. 2. 1. 3. 6. 6. 1. 2. 5. 5. 6. 5. 2. 5. 5. 6. 6.\n",
            " 1. 4. 2. 2. 6. 1. 1. 6. 1. 1. 6. 2. 6. 6. 2. 4. 2. 6. 1. 1. 5. 5. 5. 6.\n",
            " 1. 5. 2. 1. 1. 2. 5. 2. 2. 2. 6. 3. 2. 2. 6. 6. 5. 5. 5. 1. 6. 2. 5. 4.\n",
            " 3. 6. 6. 5. 5. 4. 6. 1. 2. 6. 4. 6. 4. 2. 1. 6. 2. 4. 6. 3. 2. 2. 5. 4.\n",
            " 1. 6. 6. 3. 1. 1. 2. 1. 2. 5. 2. 4.]\n",
            "valor de y_val no prepare data [6. 1. 5. 4. 2. 2. 2. 6. 5. 2. 1. 5. 1. 1. 5. 2. 6. 4. 2. 4. 6. 5. 2. 5.\n",
            " 4. 4. 6. 5. 2. 5. 2. 2. 6. 5. 2. 2. 1. 3. 5. 2. 6. 5. 1. 4. 6. 4. 5. 4.\n",
            " 4. 2. 2. 2. 4. 6. 6. 5. 2. 6. 1. 1. 2. 2. 5. 6. 3. 2. 6. 2.]\n",
            "output_directory: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC/AllCandidasBload/\n",
            "Already_done /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC/ AllCandidasBload\n",
            "\t\titer 1\n",
            "\t\t\tdataset_name:  AllCandidasBload\n",
            "valor de x_train no prepare data [[1295.   843.3 1091.  ...  846.4 1120.   497.5]\n",
            " [1486.   983.3 1471.  ...  984.7 1659.   578.5]\n",
            " [1374.   927.9  561.3 ...  915.  1371.   559.5]\n",
            " ...\n",
            " [1255.   813.1 1096.  ...  815.5 1091.   472.9]\n",
            " [1571.  1023.  1555.  ... 1027.  1561.   626.2]\n",
            " [1551.  1053.  1329.  ... 1060.  1319.   621.6]]\n",
            "valor de y_train no prepare data [5. 2. 6. 1. 4. 6. 1. 6. 2. 5. 1. 6. 1. 5. 1. 1. 6. 4. 5. 6. 6. 6. 5. 4.\n",
            " 2. 3. 5. 5. 1. 2. 6. 6. 2. 1. 5. 6. 4. 4. 2. 5. 5. 4. 6. 6. 4. 6. 2. 5.\n",
            " 6. 2. 1. 6. 6. 5. 2. 6. 5. 1. 5. 5. 6. 4. 5. 4. 5. 1. 5. 2. 4. 2. 5. 5.\n",
            " 2. 2. 4. 5. 2. 5. 2. 1. 4. 6. 2. 6. 5. 3. 4. 6. 2. 1. 2. 1. 6. 4. 6. 6.\n",
            " 6. 2. 5. 2. 2. 2. 1. 2. 2. 1. 3. 6. 6. 1. 2. 5. 5. 6. 5. 2. 5. 5. 6. 6.\n",
            " 1. 4. 2. 2. 6. 1. 1. 6. 1. 1. 6. 2. 6. 6. 2. 4. 2. 6. 1. 1. 5. 5. 5. 6.\n",
            " 1. 5. 2. 1. 1. 2. 5. 2. 2. 2. 6. 3. 2. 2. 6. 6. 5. 5. 5. 1. 6. 2. 5. 4.\n",
            " 3. 6. 6. 5. 5. 4. 6. 1. 2. 6. 4. 6. 4. 2. 1. 6. 2. 4. 6. 3. 2. 2. 5. 4.\n",
            " 1. 6. 6. 3. 1. 1. 2. 1. 2. 5. 2. 4.]\n",
            "valor de y_val no prepare data [6. 1. 5. 4. 2. 2. 2. 6. 5. 2. 1. 5. 1. 1. 5. 2. 6. 4. 2. 4. 6. 5. 2. 5.\n",
            " 4. 4. 6. 5. 2. 5. 2. 2. 6. 5. 2. 2. 1. 3. 5. 2. 6. 5. 1. 4. 6. 4. 5. 4.\n",
            " 4. 2. 2. 2. 4. 6. 6. 5. 2. 6. 1. 1. 2. 2. 5. 6. 3. 2. 6. 2.]\n",
            "output_directory: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_1/AllCandidasBload/\n",
            "Already_done /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_1/ AllCandidasBload\n",
            "\t\titer 2\n",
            "\t\t\tdataset_name:  AllCandidasBload\n",
            "valor de x_train no prepare data [[1295.   843.3 1091.  ...  846.4 1120.   497.5]\n",
            " [1486.   983.3 1471.  ...  984.7 1659.   578.5]\n",
            " [1374.   927.9  561.3 ...  915.  1371.   559.5]\n",
            " ...\n",
            " [1255.   813.1 1096.  ...  815.5 1091.   472.9]\n",
            " [1571.  1023.  1555.  ... 1027.  1561.   626.2]\n",
            " [1551.  1053.  1329.  ... 1060.  1319.   621.6]]\n",
            "valor de y_train no prepare data [5. 2. 6. 1. 4. 6. 1. 6. 2. 5. 1. 6. 1. 5. 1. 1. 6. 4. 5. 6. 6. 6. 5. 4.\n",
            " 2. 3. 5. 5. 1. 2. 6. 6. 2. 1. 5. 6. 4. 4. 2. 5. 5. 4. 6. 6. 4. 6. 2. 5.\n",
            " 6. 2. 1. 6. 6. 5. 2. 6. 5. 1. 5. 5. 6. 4. 5. 4. 5. 1. 5. 2. 4. 2. 5. 5.\n",
            " 2. 2. 4. 5. 2. 5. 2. 1. 4. 6. 2. 6. 5. 3. 4. 6. 2. 1. 2. 1. 6. 4. 6. 6.\n",
            " 6. 2. 5. 2. 2. 2. 1. 2. 2. 1. 3. 6. 6. 1. 2. 5. 5. 6. 5. 2. 5. 5. 6. 6.\n",
            " 1. 4. 2. 2. 6. 1. 1. 6. 1. 1. 6. 2. 6. 6. 2. 4. 2. 6. 1. 1. 5. 5. 5. 6.\n",
            " 1. 5. 2. 1. 1. 2. 5. 2. 2. 2. 6. 3. 2. 2. 6. 6. 5. 5. 5. 1. 6. 2. 5. 4.\n",
            " 3. 6. 6. 5. 5. 4. 6. 1. 2. 6. 4. 6. 4. 2. 1. 6. 2. 4. 6. 3. 2. 2. 5. 4.\n",
            " 1. 6. 6. 3. 1. 1. 2. 1. 2. 5. 2. 4.]\n",
            "valor de y_val no prepare data [6. 1. 5. 4. 2. 2. 2. 6. 5. 2. 1. 5. 1. 1. 5. 2. 6. 4. 2. 4. 6. 5. 2. 5.\n",
            " 4. 4. 6. 5. 2. 5. 2. 2. 6. 5. 2. 2. 1. 3. 5. 2. 6. 5. 1. 4. 6. 4. 5. 4.\n",
            " 4. 2. 2. 2. 4. 6. 6. 5. 2. 6. 1. 1. 2. 2. 5. 6. 3. 2. 6. 2.]\n",
            "output_directory: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_2/AllCandidasBload/\n",
            "Already_done /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_2/ AllCandidasBload\n",
            "\t\titer 3\n",
            "\t\t\tdataset_name:  AllCandidasBload\n",
            "valor de x_train no prepare data [[1295.   843.3 1091.  ...  846.4 1120.   497.5]\n",
            " [1486.   983.3 1471.  ...  984.7 1659.   578.5]\n",
            " [1374.   927.9  561.3 ...  915.  1371.   559.5]\n",
            " ...\n",
            " [1255.   813.1 1096.  ...  815.5 1091.   472.9]\n",
            " [1571.  1023.  1555.  ... 1027.  1561.   626.2]\n",
            " [1551.  1053.  1329.  ... 1060.  1319.   621.6]]\n",
            "valor de y_train no prepare data [5. 2. 6. 1. 4. 6. 1. 6. 2. 5. 1. 6. 1. 5. 1. 1. 6. 4. 5. 6. 6. 6. 5. 4.\n",
            " 2. 3. 5. 5. 1. 2. 6. 6. 2. 1. 5. 6. 4. 4. 2. 5. 5. 4. 6. 6. 4. 6. 2. 5.\n",
            " 6. 2. 1. 6. 6. 5. 2. 6. 5. 1. 5. 5. 6. 4. 5. 4. 5. 1. 5. 2. 4. 2. 5. 5.\n",
            " 2. 2. 4. 5. 2. 5. 2. 1. 4. 6. 2. 6. 5. 3. 4. 6. 2. 1. 2. 1. 6. 4. 6. 6.\n",
            " 6. 2. 5. 2. 2. 2. 1. 2. 2. 1. 3. 6. 6. 1. 2. 5. 5. 6. 5. 2. 5. 5. 6. 6.\n",
            " 1. 4. 2. 2. 6. 1. 1. 6. 1. 1. 6. 2. 6. 6. 2. 4. 2. 6. 1. 1. 5. 5. 5. 6.\n",
            " 1. 5. 2. 1. 1. 2. 5. 2. 2. 2. 6. 3. 2. 2. 6. 6. 5. 5. 5. 1. 6. 2. 5. 4.\n",
            " 3. 6. 6. 5. 5. 4. 6. 1. 2. 6. 4. 6. 4. 2. 1. 6. 2. 4. 6. 3. 2. 2. 5. 4.\n",
            " 1. 6. 6. 3. 1. 1. 2. 1. 2. 5. 2. 4.]\n",
            "valor de y_val no prepare data [6. 1. 5. 4. 2. 2. 2. 6. 5. 2. 1. 5. 1. 1. 5. 2. 6. 4. 2. 4. 6. 5. 2. 5.\n",
            " 4. 4. 6. 5. 2. 5. 2. 2. 6. 5. 2. 2. 1. 3. 5. 2. 6. 5. 1. 4. 6. 4. 5. 4.\n",
            " 4. 2. 2. 2. 4. 6. 6. 5. 2. 6. 1. 1. 2. 2. 5. 6. 3. 2. 6. 2.]\n",
            "output_directory: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_3/AllCandidasBload/\n",
            "Already_done /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_3/ AllCandidasBload\n",
            "\t\titer 4\n",
            "\t\t\tdataset_name:  AllCandidasBload\n",
            "valor de x_train no prepare data [[1295.   843.3 1091.  ...  846.4 1120.   497.5]\n",
            " [1486.   983.3 1471.  ...  984.7 1659.   578.5]\n",
            " [1374.   927.9  561.3 ...  915.  1371.   559.5]\n",
            " ...\n",
            " [1255.   813.1 1096.  ...  815.5 1091.   472.9]\n",
            " [1571.  1023.  1555.  ... 1027.  1561.   626.2]\n",
            " [1551.  1053.  1329.  ... 1060.  1319.   621.6]]\n",
            "valor de y_train no prepare data [5. 2. 6. 1. 4. 6. 1. 6. 2. 5. 1. 6. 1. 5. 1. 1. 6. 4. 5. 6. 6. 6. 5. 4.\n",
            " 2. 3. 5. 5. 1. 2. 6. 6. 2. 1. 5. 6. 4. 4. 2. 5. 5. 4. 6. 6. 4. 6. 2. 5.\n",
            " 6. 2. 1. 6. 6. 5. 2. 6. 5. 1. 5. 5. 6. 4. 5. 4. 5. 1. 5. 2. 4. 2. 5. 5.\n",
            " 2. 2. 4. 5. 2. 5. 2. 1. 4. 6. 2. 6. 5. 3. 4. 6. 2. 1. 2. 1. 6. 4. 6. 6.\n",
            " 6. 2. 5. 2. 2. 2. 1. 2. 2. 1. 3. 6. 6. 1. 2. 5. 5. 6. 5. 2. 5. 5. 6. 6.\n",
            " 1. 4. 2. 2. 6. 1. 1. 6. 1. 1. 6. 2. 6. 6. 2. 4. 2. 6. 1. 1. 5. 5. 5. 6.\n",
            " 1. 5. 2. 1. 1. 2. 5. 2. 2. 2. 6. 3. 2. 2. 6. 6. 5. 5. 5. 1. 6. 2. 5. 4.\n",
            " 3. 6. 6. 5. 5. 4. 6. 1. 2. 6. 4. 6. 4. 2. 1. 6. 2. 4. 6. 3. 2. 2. 5. 4.\n",
            " 1. 6. 6. 3. 1. 1. 2. 1. 2. 5. 2. 4.]\n",
            "valor de y_val no prepare data [6. 1. 5. 4. 2. 2. 2. 6. 5. 2. 1. 5. 1. 1. 5. 2. 6. 4. 2. 4. 6. 5. 2. 5.\n",
            " 4. 4. 6. 5. 2. 5. 2. 2. 6. 5. 2. 2. 1. 3. 5. 2. 6. 5. 1. 4. 6. 4. 5. 4.\n",
            " 4. 2. 2. 2. 4. 6. 6. 5. 2. 6. 1. 1. 2. 2. 5. 6. 3. 2. 6. 2.]\n",
            "output_directory: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_4/AllCandidasBload/\n",
            "Dentro do FitModel\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2s/step\n",
            "Classes before: [4 1 5 0 3 5 0 5 1 4 0 5 0 4 0 0 5 3 4 5 5 5 4 3 1 2 4 4 0 1 5 5 1 0 4 5 3\n",
            " 3 1 4 4 3 5 5 3 5 1 4 5 1 0 5 5 4 1 5 4 0 4 4 5 3 4 3 4 0 4 1 3 1 4 4 1 1\n",
            " 3 4 1 4 1 0 3 5 1 5 4 2 3 5 1 0 1 0 5 3 5 5 5 1 4 1 1 1 0 1 1 0 2 5 5 0 1\n",
            " 4 4 5 4 1 4 4 5 5 0 3 1 1 5 0 0 5 0 0 5 1 5 5 1 3 1 5 0 0 4 4 4 5 0 4 1 0\n",
            " 0 1 4 1 1 1 5 2 1 1 5 5 4 4 4 0 5 1 4 3 2 5 5 4 4 3 5 0 1 5 3 5 3 1 0 5 1\n",
            " 3 5 2 1 1 4 3 0 5 5 2 0 0 1 0 1 4 1 3]\n",
            "Classes after: [0 1 2 3 4 5]\n",
            "Y_pred: [5 4 5 1 0 5 1 3 3 5 1 2 1 1 0 1 4 3 5 5 5 1 4 4 1 4 5 1 4 1 3 4 0 0 0 5 5\n",
            " 4 1 1 2 0 1 3 4 4 1 1 3 5 3 5 5 4 1 5 0 1 1 0 5 3 0 5 1 1 1 1]\n",
            "y_val [5 4 5 1 0 5 1 3 3 5 1 2 1 1 0 1 1 3 5 5 5 1 4 4 1 4 5 1 4 1 0 4 0 0 0 5 5\n",
            " 4 1 1 2 0 1 3 4 4 1 1 3 5 3 5 5 4 1 5 0 1 1 0 5 3 0 5 1 1 1 1]\n",
            "y_pred before save =  \n",
            " [[5.74094011e-05 6.50419815e-06 7.67592780e-07 8.28958309e-06\n",
            "  2.28758654e-06 9.99924779e-01]\n",
            " [2.94819038e-05 1.48731806e-06 4.86048202e-06 5.21335518e-04\n",
            "  9.99153614e-01 2.89170595e-04]\n",
            " [3.21883846e-07 3.26748442e-08 1.69380246e-10 5.62217028e-09\n",
            "  1.15854182e-09 9.99999642e-01]\n",
            " [3.01525695e-03 9.93267655e-01 2.89951040e-05 2.48963037e-03\n",
            "  4.90908633e-06 1.19365798e-03]\n",
            " [9.99800384e-01 1.18986412e-04 2.76009953e-08 1.62213803e-06\n",
            "  5.49964589e-08 7.89930928e-05]\n",
            " [1.63924589e-04 3.67309549e-05 1.06813186e-05 5.46171532e-06\n",
            "  6.11584182e-05 9.99722064e-01]\n",
            " [1.91410858e-04 9.98499274e-01 1.32915266e-05 1.04869297e-03\n",
            "  2.24827338e-04 2.24580363e-05]\n",
            " [1.84202042e-06 4.08286360e-06 1.54062957e-06 9.99965191e-01\n",
            "  2.68016884e-05 4.52993476e-07]\n",
            " [1.80456971e-06 3.35902883e-09 1.45402190e-09 9.99986529e-01\n",
            "  1.12240959e-05 4.90809725e-07]\n",
            " [2.82709352e-05 2.40604841e-05 6.65786547e-06 6.93547122e-07\n",
            "  1.05859417e-05 9.99929786e-01]\n",
            " [4.50152264e-04 9.96608615e-01 3.09166826e-05 6.28158159e-05\n",
            "  2.82292021e-03 2.45815099e-05]\n",
            " [4.00902500e-05 8.21025968e-02 9.17835176e-01 2.08400234e-05\n",
            "  1.75355751e-07 1.10184430e-06]\n",
            " [7.19992750e-05 9.99881864e-01 4.33841979e-06 3.20811705e-05\n",
            "  7.07376012e-06 2.77188178e-06]\n",
            " [1.05540337e-07 9.99988675e-01 1.00092302e-05 1.08529230e-09\n",
            "  2.91508750e-09 1.22110305e-06]\n",
            " [9.99874592e-01 6.14438904e-05 2.58409159e-07 3.65467258e-06\n",
            "  2.18775381e-06 5.79647894e-05]\n",
            " [1.12753523e-05 9.99968052e-01 3.49247148e-06 8.34110870e-06\n",
            "  4.83464601e-06 3.98617794e-06]\n",
            " [4.11128596e-04 4.43175122e-05 8.72678538e-06 5.38650081e-02\n",
            "  9.44300473e-01 1.37041637e-03]\n",
            " [2.08669718e-07 1.45030441e-04 3.04729906e-06 9.99851108e-01\n",
            "  5.45603939e-07 4.35331993e-09]\n",
            " [2.80196691e-05 4.62382741e-05 1.55884949e-09 1.03039222e-08\n",
            "  3.95075395e-09 9.99925733e-01]\n",
            " [1.81017924e-04 5.95263846e-04 1.55592406e-05 2.10068501e-05\n",
            "  7.15428905e-05 9.99115646e-01]\n",
            " [5.14866661e-05 2.41356975e-04 9.46520959e-06 4.00682802e-06\n",
            "  2.48248925e-05 9.99668837e-01]\n",
            " [2.86297947e-01 7.13368714e-01 5.35044986e-09 4.60594984e-09\n",
            "  1.45907322e-07 3.33194330e-04]\n",
            " [1.55724920e-05 4.60517128e-07 1.56261592e-06 3.19894956e-04\n",
            "  9.99520302e-01 1.42293400e-04]\n",
            " [1.92650233e-03 5.10131428e-03 1.09318469e-04 1.88631453e-02\n",
            "  9.69680071e-01 4.31967713e-03]\n",
            " [3.58449288e-05 9.99790847e-01 1.27168710e-06 1.57471673e-04\n",
            "  1.35930741e-05 9.53690346e-07]\n",
            " [1.48808313e-05 9.50352216e-07 3.08982203e-06 7.95923115e-05\n",
            "  9.99778688e-01 1.22745929e-04]\n",
            " [2.41441776e-05 2.23196321e-06 1.98968678e-06 3.68970336e-06\n",
            "  4.66180099e-05 9.99921322e-01]\n",
            " [1.36861205e-03 9.89612281e-01 6.09545503e-04 1.61652558e-03\n",
            "  5.97662060e-03 8.16304411e-04]\n",
            " [4.50830157e-05 4.35841457e-06 9.64898663e-06 2.09251681e-04\n",
            "  9.99409556e-01 3.22179170e-04]\n",
            " [1.43655940e-04 9.99841452e-01 1.18558091e-05 2.98460759e-06\n",
            "  3.64709685e-08 8.02259237e-08]\n",
            " [2.65097287e-06 8.26853327e-04 1.74950389e-03 9.97407377e-01\n",
            "  1.33442327e-05 2.07577273e-07]\n",
            " [6.75446281e-05 8.33078593e-06 1.92427087e-05 5.69053227e-04\n",
            "  9.98822987e-01 5.12803847e-04]\n",
            " [9.98747587e-01 6.37453923e-04 6.97133655e-05 3.00297634e-05\n",
            "  1.32115389e-07 5.15072315e-04]\n",
            " [9.99690413e-01 2.64694972e-04 1.80346067e-08 4.50269818e-06\n",
            "  2.36870264e-07 4.01550897e-05]\n",
            " [9.94818151e-01 5.15865674e-03 7.39089637e-06 6.17035084e-06\n",
            "  6.11393318e-07 9.13496751e-06]\n",
            " [7.94575535e-05 9.16801673e-06 1.66341896e-09 1.05269162e-08\n",
            "  6.83076395e-09 9.99911308e-01]\n",
            " [2.05449778e-05 1.91706613e-06 1.53622057e-06 2.83093095e-06\n",
            "  3.49698821e-05 9.99938250e-01]\n",
            " [1.27369713e-05 6.87592092e-07 2.40180088e-06 8.60304572e-05\n",
            "  9.99798954e-01 9.91470806e-05]\n",
            " [4.23242757e-03 8.78579140e-01 4.81885113e-03 1.40343988e-02\n",
            "  9.59534124e-02 2.38178275e-03]\n",
            " [1.48696316e-04 9.99733865e-01 1.32469711e-06 9.15952623e-05\n",
            "  1.78958162e-05 6.60468959e-06]\n",
            " [2.35592120e-06 3.29800881e-03 9.96699274e-01 2.72077301e-07\n",
            "  1.40721799e-08 1.70261131e-07]\n",
            " [9.96944010e-01 2.96802373e-05 2.64954156e-06 2.90533714e-03\n",
            "  8.65846087e-05 3.17359554e-05]\n",
            " [3.72514046e-06 9.99993563e-01 1.32834606e-08 2.18410105e-06\n",
            "  4.41371128e-07 1.77916931e-07]\n",
            " [6.70427180e-09 2.42985607e-06 5.42216538e-09 9.99997616e-01\n",
            "  7.90755372e-09 5.13714314e-11]\n",
            " [5.76330131e-05 5.24274628e-06 1.18263106e-05 5.22854854e-04\n",
            "  9.98973012e-01 4.29416716e-04]\n",
            " [7.88293710e-06 3.47692406e-07 1.30423280e-06 4.51685664e-05\n",
            "  9.99884248e-01 6.10749048e-05]\n",
            " [3.64099606e-03 9.40369546e-01 5.19589114e-04 4.02491689e-02\n",
            "  1.44773452e-02 7.43324403e-04]\n",
            " [2.08441447e-03 8.99220645e-01 1.83177006e-04 8.36187154e-02\n",
            "  1.41839702e-02 7.09101092e-04]\n",
            " [3.18778461e-08 4.27490486e-05 3.63126310e-05 9.99919772e-01\n",
            "  1.08235520e-06 1.66102987e-09]\n",
            " [1.46449638e-05 2.74317858e-06 1.62116180e-06 6.41308191e-07\n",
            "  2.58085292e-05 9.99954581e-01]\n",
            " [7.83215569e-07 1.65371515e-04 4.45902651e-06 9.99827743e-01\n",
            "  1.70417843e-06 2.51811514e-08]\n",
            " [4.16134513e-04 4.56045746e-06 9.09439314e-06 3.93905975e-05\n",
            "  6.04424968e-05 9.99470413e-01]\n",
            " [2.34564759e-05 5.43121569e-05 5.56313398e-06 1.31622505e-06\n",
            "  1.43579346e-05 9.99900937e-01]\n",
            " [2.89891632e-05 1.18464360e-03 2.76805054e-06 8.32541446e-06\n",
            "  9.98729408e-01 4.58150316e-05]\n",
            " [2.36316865e-07 9.99994874e-01 7.07111951e-08 3.19609444e-06\n",
            "  1.03878319e-08 1.56477779e-06]\n",
            " [9.63450148e-05 9.19306331e-06 1.10175770e-05 1.32806126e-05\n",
            "  2.47213939e-05 9.99845386e-01]\n",
            " [9.99787152e-01 5.20595568e-05 6.85045407e-08 3.10830205e-06\n",
            "  1.10594634e-07 1.57393311e-04]\n",
            " [9.27062720e-05 9.90147054e-01 7.15051312e-03 2.55222875e-03\n",
            "  1.08124495e-05 4.65674748e-05]\n",
            " [3.06509683e-05 9.98880804e-01 2.05108445e-05 1.06702233e-03\n",
            "  1.71075698e-07 9.80688696e-07]\n",
            " [9.97082412e-01 2.82358215e-03 6.73981849e-05 1.57499016e-05\n",
            "  7.84953897e-07 9.99840358e-06]\n",
            " [4.11607252e-05 8.37422249e-06 3.44216369e-06 8.32008482e-06\n",
            "  9.06767400e-06 9.99929667e-01]\n",
            " [2.93344513e-08 1.56074220e-05 4.65209814e-06 9.99979258e-01\n",
            "  5.34961941e-07 1.29677624e-09]\n",
            " [9.99765933e-01 9.62397462e-05 1.07769466e-07 3.04947548e-06\n",
            "  9.46698648e-08 1.34453541e-04]\n",
            " [1.28895044e-04 2.10570743e-05 8.87265996e-05 1.40261875e-06\n",
            "  1.51337845e-05 9.99744833e-01]\n",
            " [2.71748604e-07 9.99738395e-01 2.52702681e-04 1.13396983e-11\n",
            "  2.81495632e-10 8.73443332e-06]\n",
            " [1.46257617e-06 9.99945760e-01 3.11363656e-05 6.19854434e-09\n",
            "  2.77455801e-08 2.16768804e-05]\n",
            " [1.32372908e-04 9.85520661e-01 1.41671700e-02 3.74805932e-05\n",
            "  5.01931368e-07 1.41803626e-04]\n",
            " [1.75262940e-07 9.99998808e-01 2.99304276e-07 8.39383247e-08\n",
            "  1.07638009e-07 4.37151698e-07]]\n",
            "Histórico\n",
            "      accuracy  false_negatives  false_positives      loss  precision  \\\n",
            "0     0.534314            139.0             28.0  1.297642   0.698925   \n",
            "1     0.794118             51.0             32.0  0.562079   0.827027   \n",
            "2     0.843137             35.0             29.0  0.459425   0.853535   \n",
            "3     0.833333             43.0             16.0  0.400375   0.909605   \n",
            "4     0.843137             42.0             16.0  0.384172   0.910112   \n",
            "...        ...              ...              ...       ...        ...   \n",
            "1495  1.000000              0.0              0.0  0.001348   1.000000   \n",
            "1496  1.000000              0.0              0.0  0.004690   1.000000   \n",
            "1497  0.995098              1.0              1.0  0.007814   0.995098   \n",
            "1498  0.995098              1.0              1.0  0.005750   0.995098   \n",
            "1499  1.000000              0.0              0.0  0.001425   1.000000   \n",
            "\n",
            "        recall  true_negatives  true_positives  learning_rate  \n",
            "0     0.318627           992.0            65.0         0.0010  \n",
            "1     0.750000           988.0           153.0         0.0010  \n",
            "2     0.828431           991.0           169.0         0.0010  \n",
            "3     0.789216          1004.0           161.0         0.0010  \n",
            "4     0.794118          1004.0           162.0         0.0010  \n",
            "...        ...             ...             ...            ...  \n",
            "1495  1.000000          1020.0           204.0         0.0001  \n",
            "1496  1.000000          1020.0           204.0         0.0001  \n",
            "1497  0.995098          1019.0           203.0         0.0001  \n",
            "1498  0.995098          1019.0           203.0         0.0001  \n",
            "1499  1.000000          1020.0           204.0         0.0001  \n",
            "\n",
            "[1500 rows x 9 columns]\n",
            "Temp: 0.9640151515151515\n",
            "   precision  accuracy    recall  f1_score    duration  std  specificity\n",
            "0   0.964015  0.970588  0.976087  0.968477  372.577648  0.0     0.994394\n",
            "\t\t\t\tDONE\n",
            "\t\titer 5\n",
            "\t\t\tdataset_name:  AllCandidasBload\n",
            "valor de x_train no prepare data [[1295.   843.3 1091.  ...  846.4 1120.   497.5]\n",
            " [1486.   983.3 1471.  ...  984.7 1659.   578.5]\n",
            " [1374.   927.9  561.3 ...  915.  1371.   559.5]\n",
            " ...\n",
            " [1255.   813.1 1096.  ...  815.5 1091.   472.9]\n",
            " [1571.  1023.  1555.  ... 1027.  1561.   626.2]\n",
            " [1551.  1053.  1329.  ... 1060.  1319.   621.6]]\n",
            "valor de y_train no prepare data [5. 2. 6. 1. 4. 6. 1. 6. 2. 5. 1. 6. 1. 5. 1. 1. 6. 4. 5. 6. 6. 6. 5. 4.\n",
            " 2. 3. 5. 5. 1. 2. 6. 6. 2. 1. 5. 6. 4. 4. 2. 5. 5. 4. 6. 6. 4. 6. 2. 5.\n",
            " 6. 2. 1. 6. 6. 5. 2. 6. 5. 1. 5. 5. 6. 4. 5. 4. 5. 1. 5. 2. 4. 2. 5. 5.\n",
            " 2. 2. 4. 5. 2. 5. 2. 1. 4. 6. 2. 6. 5. 3. 4. 6. 2. 1. 2. 1. 6. 4. 6. 6.\n",
            " 6. 2. 5. 2. 2. 2. 1. 2. 2. 1. 3. 6. 6. 1. 2. 5. 5. 6. 5. 2. 5. 5. 6. 6.\n",
            " 1. 4. 2. 2. 6. 1. 1. 6. 1. 1. 6. 2. 6. 6. 2. 4. 2. 6. 1. 1. 5. 5. 5. 6.\n",
            " 1. 5. 2. 1. 1. 2. 5. 2. 2. 2. 6. 3. 2. 2. 6. 6. 5. 5. 5. 1. 6. 2. 5. 4.\n",
            " 3. 6. 6. 5. 5. 4. 6. 1. 2. 6. 4. 6. 4. 2. 1. 6. 2. 4. 6. 3. 2. 2. 5. 4.\n",
            " 1. 6. 6. 3. 1. 1. 2. 1. 2. 5. 2. 4.]\n",
            "valor de y_val no prepare data [6. 1. 5. 4. 2. 2. 2. 6. 5. 2. 1. 5. 1. 1. 5. 2. 6. 4. 2. 4. 6. 5. 2. 5.\n",
            " 4. 4. 6. 5. 2. 5. 2. 2. 6. 5. 2. 2. 1. 3. 5. 2. 6. 5. 1. 4. 6. 4. 5. 4.\n",
            " 4. 2. 2. 2. 4. 6. 6. 5. 2. 6. 1. 1. 2. 2. 5. 6. 3. 2. 6. 2.]\n",
            "output_directory: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_5/AllCandidasBload/\n",
            "Dentro do FitModel\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 901ms/step\n",
            "Classes before: [4 1 5 0 3 5 0 5 1 4 0 5 0 4 0 0 5 3 4 5 5 5 4 3 1 2 4 4 0 1 5 5 1 0 4 5 3\n",
            " 3 1 4 4 3 5 5 3 5 1 4 5 1 0 5 5 4 1 5 4 0 4 4 5 3 4 3 4 0 4 1 3 1 4 4 1 1\n",
            " 3 4 1 4 1 0 3 5 1 5 4 2 3 5 1 0 1 0 5 3 5 5 5 1 4 1 1 1 0 1 1 0 2 5 5 0 1\n",
            " 4 4 5 4 1 4 4 5 5 0 3 1 1 5 0 0 5 0 0 5 1 5 5 1 3 1 5 0 0 4 4 4 5 0 4 1 0\n",
            " 0 1 4 1 1 1 5 2 1 1 5 5 4 4 4 0 5 1 4 3 2 5 5 4 4 3 5 0 1 5 3 5 3 1 0 5 1\n",
            " 3 5 2 1 1 4 3 0 5 5 2 0 0 1 0 1 4 1 3]\n",
            "Classes after: [0 1 2 3 4 5]\n",
            "Y_pred: [5 4 5 0 0 5 1 3 3 5 1 1 1 1 0 1 4 3 5 5 5 1 4 3 1 4 5 1 4 1 3 4 0 0 0 5 5\n",
            " 4 3 1 2 0 1 3 4 4 3 3 3 5 3 5 5 4 1 5 0 1 1 0 5 3 0 5 1 1 1 1]\n",
            "y_val [5 4 5 1 0 5 1 3 3 5 1 2 1 1 0 1 1 3 5 5 5 1 4 4 1 4 5 1 4 1 0 4 0 0 0 5 5\n",
            " 4 1 1 2 0 1 3 4 4 1 1 3 5 3 5 5 4 1 5 0 1 1 0 5 3 0 5 1 1 1 1]\n",
            "y_pred before save =  \n",
            " [[4.89336671e-05 5.59508123e-07 3.35017063e-07 1.33323520e-05\n",
            "  3.58677653e-06 9.99933243e-01]\n",
            " [4.59373041e-05 4.98067720e-07 7.97402572e-06 1.22166864e-04\n",
            "  9.99591529e-01 2.31834420e-04]\n",
            " [1.15903993e-06 6.66936231e-08 1.34185874e-09 6.23241334e-08\n",
            "  8.50423021e-09 9.99998689e-01]\n",
            " [6.58472359e-01 3.26748908e-01 3.63221119e-07 1.37391649e-02\n",
            "  7.23209865e-08 1.03913655e-03]\n",
            " [9.99892950e-01 8.71638986e-05 6.09628215e-09 9.49430250e-06\n",
            "  2.27473834e-07 1.01877658e-05]\n",
            " [4.21202458e-06 1.20023287e-05 2.27219925e-06 8.60713158e-07\n",
            "  9.17379930e-06 9.99971509e-01]\n",
            " [4.77417871e-06 9.10103321e-01 1.65584279e-05 8.96744877e-02\n",
            "  1.83014636e-04 1.78116425e-05]\n",
            " [9.58216262e-09 3.68574570e-06 1.81579381e-07 9.99987721e-01\n",
            "  8.34037291e-06 1.93415524e-08]\n",
            " [1.11899737e-06 3.19469422e-07 1.86136162e-09 9.99982595e-01\n",
            "  1.57542036e-05 2.36368507e-07]\n",
            " [6.58827219e-07 1.89098694e-06 7.78192373e-07 5.21338563e-08\n",
            "  6.42854559e-07 9.99995947e-01]\n",
            " [1.24462395e-06 9.84215438e-01 2.11014185e-06 1.54375546e-02\n",
            "  3.38165351e-04 5.55668976e-06]\n",
            " [4.35833680e-03 8.07351112e-01 1.88083455e-01 1.99185248e-04\n",
            "  1.23885638e-06 6.63867240e-06]\n",
            " [3.35890675e-08 9.99747455e-01 3.91400601e-09 2.52078433e-04\n",
            "  3.51735366e-07 1.66036202e-07]\n",
            " [4.96737984e-10 9.99999881e-01 1.79172444e-09 5.71746261e-10\n",
            "  2.48844945e-10 8.68758931e-08]\n",
            " [9.99942422e-01 4.32896377e-05 2.67171014e-08 5.02879493e-06\n",
            "  1.73883518e-06 7.47844797e-06]\n",
            " [8.84553231e-08 9.99288917e-01 3.98865154e-08 7.09191780e-04\n",
            "  4.54958524e-07 1.30782541e-06]\n",
            " [3.26072593e-04 1.00620068e-03 1.29645341e-04 3.30636710e-01\n",
            "  6.67407990e-01 4.93381056e-04]\n",
            " [3.82753662e-10 1.82631356e-05 6.10498176e-08 9.99981403e-01\n",
            "  1.97243082e-07 5.92688176e-10]\n",
            " [4.21717297e-03 2.22522984e-04 1.82623587e-08 3.41029636e-06\n",
            "  2.79451115e-07 9.95556653e-01]\n",
            " [1.09510638e-05 1.59996140e-04 3.70456110e-06 4.47716184e-06\n",
            "  1.97984464e-05 9.99801099e-01]\n",
            " [2.52428981e-06 2.93794656e-05 1.94184622e-06 5.29976376e-07\n",
            "  3.44043769e-06 9.99962211e-01]\n",
            " [2.14897409e-01 7.84920871e-01 1.08083154e-10 1.15952825e-09\n",
            "  5.54999546e-10 1.81711614e-04]\n",
            " [2.92585719e-05 1.31887390e-07 2.29033867e-06 5.71767814e-05\n",
            "  9.99794781e-01 1.16288422e-04]\n",
            " [1.55707786e-03 4.02016714e-02 3.31539707e-03 4.85014945e-01\n",
            "  4.67833966e-01 2.07689684e-03]\n",
            " [1.67134971e-07 9.97551501e-01 6.30955110e-09 2.44717789e-03\n",
            "  8.13146357e-07 4.07107621e-07]\n",
            " [2.51920028e-05 2.60711715e-07 5.25007590e-06 8.10749589e-06\n",
            "  9.99857426e-01 1.03658436e-04]\n",
            " [9.25892982e-06 1.93155749e-08 8.90150432e-07 5.69690826e-07\n",
            "  8.50366996e-06 9.99980807e-01]\n",
            " [1.99741453e-06 7.61387229e-01 4.06501495e-04 2.37237006e-01\n",
            "  9.35278891e-04 3.19961437e-05]\n",
            " [4.09813038e-05 8.77991795e-07 9.83790596e-06 1.51081031e-05\n",
            "  9.99744952e-01 1.88133432e-04]\n",
            " [5.07172314e-04 9.98865485e-01 1.18021160e-06 6.20900188e-04\n",
            "  4.46190086e-07 4.87709303e-06]\n",
            " [6.08168591e-07 1.86668753e-04 4.06623258e-07 9.99808371e-01\n",
            "  3.79920198e-06 1.19001818e-07]\n",
            " [7.21151227e-05 2.68873964e-06 2.33722203e-05 7.50151157e-05\n",
            "  9.99487877e-01 3.38830403e-04]\n",
            " [9.87483919e-01 1.12117333e-02 9.87136332e-07 1.11516158e-03\n",
            "  1.44032822e-06 1.86811958e-04]\n",
            " [9.99880552e-01 9.63004495e-05 6.29062091e-09 1.47567916e-05\n",
            "  4.48923942e-07 7.85804059e-06]\n",
            " [9.99990940e-01 9.11216375e-06 1.46875401e-09 1.33663045e-08\n",
            "  5.43055574e-12 1.93124574e-08]\n",
            " [3.69059145e-02 5.98505212e-05 6.20448226e-09 2.43488876e-06\n",
            "  1.65750777e-07 9.63031590e-01]\n",
            " [8.34327693e-06 1.67642149e-08 7.30503587e-07 4.61275448e-07\n",
            "  6.49229969e-06 9.99983907e-01]\n",
            " [2.27824767e-05 1.89713333e-07 4.13783027e-06 9.12662381e-06\n",
            "  9.99878883e-01 8.48670170e-05]\n",
            " [1.58995908e-06 3.55057687e-01 1.13705627e-03 6.37699723e-01\n",
            "  6.07839879e-03 2.54434217e-05]\n",
            " [1.33748188e-06 9.76193428e-01 1.88758307e-07 2.37912126e-02\n",
            "  1.08023996e-05 2.97821975e-06]\n",
            " [7.69142644e-05 1.80818047e-02 9.81840312e-01 6.56638974e-07\n",
            "  6.70982558e-08 1.21757679e-07]\n",
            " [9.99896169e-01 2.11185506e-05 4.84722413e-08 8.15916283e-05\n",
            "  2.97219582e-08 1.03805098e-06]\n",
            " [3.06390064e-07 9.99854684e-01 1.06720321e-09 1.44063379e-04\n",
            "  1.68892726e-07 7.44621275e-07]\n",
            " [3.79707168e-11 3.12163536e-07 1.83820528e-10 9.99999642e-01\n",
            "  2.11541664e-08 1.95899165e-11]\n",
            " [6.11080177e-05 1.52884240e-06 1.30213857e-05 6.43783060e-05\n",
            "  9.99601543e-01 2.58409709e-04]\n",
            " [1.64196772e-05 9.31863298e-08 2.48063702e-06 4.48372157e-06\n",
            "  9.99920487e-01 5.60391200e-05]\n",
            " [1.02829040e-06 1.98992774e-01 4.56887246e-05 8.00154805e-01\n",
            "  7.99532339e-04 6.19424418e-06]\n",
            " [9.22478648e-05 4.48526949e-01 1.57897055e-04 5.48076808e-01\n",
            "  3.01433448e-03 1.31765977e-04]\n",
            " [3.83409832e-11 8.70899294e-06 9.50119500e-07 9.99989629e-01\n",
            "  6.91987736e-07 2.08223161e-10]\n",
            " [1.06505922e-06 7.53625145e-08 6.86401847e-07 2.40940174e-08\n",
            "  2.50981770e-06 9.99995589e-01]\n",
            " [1.63023484e-09 2.48888809e-05 1.11570344e-07 9.99974370e-01\n",
            "  5.42513760e-07 2.32997155e-09]\n",
            " [6.69386282e-05 3.02156593e-07 3.23008067e-06 4.19440266e-06\n",
            "  1.30076442e-05 9.99912262e-01]\n",
            " [1.14259069e-06 3.28889951e-06 1.04078924e-06 1.00810730e-07\n",
            "  1.53297628e-06 9.99992847e-01]\n",
            " [3.97022450e-05 8.64879508e-03 3.67173314e-04 8.30749981e-04\n",
            "  9.90018368e-01 9.52109403e-05]\n",
            " [1.22782268e-07 9.99842644e-01 3.78056614e-10 1.41083379e-04\n",
            "  1.30637978e-09 1.60388336e-05]\n",
            " [2.83301379e-05 1.79321361e-07 2.30293699e-06 2.58366981e-06\n",
            "  4.88922115e-06 9.99961734e-01]\n",
            " [9.99867320e-01 9.45602296e-05 1.23227135e-08 1.65691799e-05\n",
            "  4.76960111e-07 2.11426650e-05]\n",
            " [8.90878340e-08 9.30971980e-01 4.24225836e-05 6.89796954e-02\n",
            "  9.20080083e-07 4.88716842e-06]\n",
            " [1.33152196e-06 9.98374581e-01 1.01919490e-07 1.62319839e-03\n",
            "  2.05154596e-08 7.51672360e-07]\n",
            " [9.99994755e-01 5.27121711e-06 9.15147069e-09 1.16407879e-08\n",
            "  3.92741308e-12 9.39139255e-09]\n",
            " [1.36126646e-05 1.20876720e-07 1.08523045e-06 1.18707590e-06\n",
            "  2.38007442e-06 9.99981642e-01]\n",
            " [4.92590031e-11 3.55779775e-06 1.59189312e-07 9.99995947e-01\n",
            "  4.15764077e-07 1.73401626e-10]\n",
            " [9.99840975e-01 1.23778635e-04 1.48046730e-08 1.71630727e-05\n",
            "  4.39499502e-07 1.75925179e-05]\n",
            " [8.91832224e-06 2.64999608e-06 1.83587435e-05 2.88083299e-07\n",
            "  3.64786138e-06 9.99966145e-01]\n",
            " [9.31035693e-10 1.00000000e+00 2.05858530e-08 1.07669483e-12\n",
            "  4.96699834e-11 3.02154959e-08]\n",
            " [2.53347254e-09 9.99999523e-01 1.85933242e-08 9.89016513e-09\n",
            "  3.40257289e-09 4.90665400e-07]\n",
            " [1.75451100e-06 9.99937415e-01 2.47434582e-05 3.35876175e-05\n",
            "  5.90084248e-08 2.42175634e-06]\n",
            " [5.70798075e-09 9.99999046e-01 1.15781662e-09 2.45857336e-07\n",
            "  1.26377939e-08 7.31270234e-07]]\n",
            "Histórico\n",
            "      accuracy  false_negatives  false_positives      loss  precision  \\\n",
            "0     0.553922            128.0             17.0  1.295350   0.817204   \n",
            "1     0.779412             63.0             21.0  0.552702   0.870370   \n",
            "2     0.828431             39.0             26.0  0.450976   0.863874   \n",
            "3     0.823529             46.0             27.0  0.438370   0.854054   \n",
            "4     0.862745             51.0             13.0  0.419260   0.921687   \n",
            "...        ...              ...              ...       ...        ...   \n",
            "1495  1.000000              0.0              0.0  0.002890   1.000000   \n",
            "1496  1.000000              0.0              0.0  0.003597   1.000000   \n",
            "1497  1.000000              0.0              0.0  0.005701   1.000000   \n",
            "1498  1.000000              0.0              0.0  0.003138   1.000000   \n",
            "1499  1.000000              0.0              0.0  0.003847   1.000000   \n",
            "\n",
            "        recall  true_negatives  true_positives  learning_rate  \n",
            "0     0.372549          1003.0            76.0         0.0010  \n",
            "1     0.691176           999.0           141.0         0.0010  \n",
            "2     0.808824           994.0           165.0         0.0010  \n",
            "3     0.774510           993.0           158.0         0.0010  \n",
            "4     0.750000          1007.0           153.0         0.0010  \n",
            "...        ...             ...             ...            ...  \n",
            "1495  1.000000          1020.0           204.0         0.0001  \n",
            "1496  1.000000          1020.0           204.0         0.0001  \n",
            "1497  1.000000          1020.0           204.0         0.0001  \n",
            "1498  1.000000          1020.0           204.0         0.0001  \n",
            "1499  1.000000          1020.0           204.0         0.0001  \n",
            "\n",
            "[1500 rows x 9 columns]\n",
            "Temp: 0.8884502923976608\n",
            "   precision  accuracy    recall  f1_score    duration  std  specificity\n",
            "0    0.88845  0.882353  0.847101  0.843442  373.402907  0.0     0.976888\n",
            "\t\t\t\tDONE\n",
            "\t\titer 6\n",
            "\t\t\tdataset_name:  AllCandidasBload\n",
            "valor de x_train no prepare data [[1295.   843.3 1091.  ...  846.4 1120.   497.5]\n",
            " [1486.   983.3 1471.  ...  984.7 1659.   578.5]\n",
            " [1374.   927.9  561.3 ...  915.  1371.   559.5]\n",
            " ...\n",
            " [1255.   813.1 1096.  ...  815.5 1091.   472.9]\n",
            " [1571.  1023.  1555.  ... 1027.  1561.   626.2]\n",
            " [1551.  1053.  1329.  ... 1060.  1319.   621.6]]\n",
            "valor de y_train no prepare data [5. 2. 6. 1. 4. 6. 1. 6. 2. 5. 1. 6. 1. 5. 1. 1. 6. 4. 5. 6. 6. 6. 5. 4.\n",
            " 2. 3. 5. 5. 1. 2. 6. 6. 2. 1. 5. 6. 4. 4. 2. 5. 5. 4. 6. 6. 4. 6. 2. 5.\n",
            " 6. 2. 1. 6. 6. 5. 2. 6. 5. 1. 5. 5. 6. 4. 5. 4. 5. 1. 5. 2. 4. 2. 5. 5.\n",
            " 2. 2. 4. 5. 2. 5. 2. 1. 4. 6. 2. 6. 5. 3. 4. 6. 2. 1. 2. 1. 6. 4. 6. 6.\n",
            " 6. 2. 5. 2. 2. 2. 1. 2. 2. 1. 3. 6. 6. 1. 2. 5. 5. 6. 5. 2. 5. 5. 6. 6.\n",
            " 1. 4. 2. 2. 6. 1. 1. 6. 1. 1. 6. 2. 6. 6. 2. 4. 2. 6. 1. 1. 5. 5. 5. 6.\n",
            " 1. 5. 2. 1. 1. 2. 5. 2. 2. 2. 6. 3. 2. 2. 6. 6. 5. 5. 5. 1. 6. 2. 5. 4.\n",
            " 3. 6. 6. 5. 5. 4. 6. 1. 2. 6. 4. 6. 4. 2. 1. 6. 2. 4. 6. 3. 2. 2. 5. 4.\n",
            " 1. 6. 6. 3. 1. 1. 2. 1. 2. 5. 2. 4.]\n",
            "valor de y_val no prepare data [6. 1. 5. 4. 2. 2. 2. 6. 5. 2. 1. 5. 1. 1. 5. 2. 6. 4. 2. 4. 6. 5. 2. 5.\n",
            " 4. 4. 6. 5. 2. 5. 2. 2. 6. 5. 2. 2. 1. 3. 5. 2. 6. 5. 1. 4. 6. 4. 5. 4.\n",
            " 4. 2. 2. 2. 4. 6. 6. 5. 2. 6. 1. 1. 2. 2. 5. 6. 3. 2. 6. 2.]\n",
            "output_directory: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_6/AllCandidasBload/\n",
            "Dentro do FitModel\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x796992119e40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 946ms/step"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x796992119e40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 895ms/step\n",
            "Classes before: [4 1 5 0 3 5 0 5 1 4 0 5 0 4 0 0 5 3 4 5 5 5 4 3 1 2 4 4 0 1 5 5 1 0 4 5 3\n",
            " 3 1 4 4 3 5 5 3 5 1 4 5 1 0 5 5 4 1 5 4 0 4 4 5 3 4 3 4 0 4 1 3 1 4 4 1 1\n",
            " 3 4 1 4 1 0 3 5 1 5 4 2 3 5 1 0 1 0 5 3 5 5 5 1 4 1 1 1 0 1 1 0 2 5 5 0 1\n",
            " 4 4 5 4 1 4 4 5 5 0 3 1 1 5 0 0 5 0 0 5 1 5 5 1 3 1 5 0 0 4 4 4 5 0 4 1 0\n",
            " 0 1 4 1 1 1 5 2 1 1 5 5 4 4 4 0 5 1 4 3 2 5 5 4 4 3 5 0 1 5 3 5 3 1 0 5 1\n",
            " 3 5 2 1 1 4 3 0 5 5 2 0 0 1 0 1 4 1 3]\n",
            "Classes after: [0 1 2 3 4 5]\n",
            "Y_pred: [5 4 5 1 0 5 1 3 3 5 4 2 1 1 0 1 4 3 5 5 5 1 4 4 1 4 5 1 4 1 3 4 0 0 0 5 5\n",
            " 4 4 1 2 0 1 3 4 4 1 1 3 5 3 5 5 4 1 5 0 1 1 0 5 3 0 5 1 1 1 1]\n",
            "y_val [5 4 5 1 0 5 1 3 3 5 1 2 1 1 0 1 1 3 5 5 5 1 4 4 1 4 5 1 4 1 0 4 0 0 0 5 5\n",
            " 4 1 1 2 0 1 3 4 4 1 1 3 5 3 5 5 4 1 5 0 1 1 0 5 3 0 5 1 1 1 1]\n",
            "y_pred before save =  \n",
            " [[1.72553671e-04 1.86161424e-06 6.27118823e-07 1.36762060e-06\n",
            "  9.20310413e-06 9.99814451e-01]\n",
            " [2.46872169e-05 3.20739559e-07 1.97003078e-06 1.52609544e-04\n",
            "  9.99655128e-01 1.65324673e-04]\n",
            " [2.10139592e-06 2.48001726e-08 1.16311871e-09 6.06905282e-09\n",
            "  8.54893134e-09 9.99997854e-01]\n",
            " [1.03283813e-03 9.97819066e-01 1.68352869e-07 2.59918088e-05\n",
            "  5.18675188e-05 1.07012573e-03]\n",
            " [9.99996305e-01 3.29878844e-07 4.16049328e-09 1.47462362e-08\n",
            "  2.47021785e-06 8.93424954e-07]\n",
            " [1.63377663e-05 4.63486003e-06 9.74679324e-07 8.41172152e-07\n",
            "  2.42587048e-05 9.99952912e-01]\n",
            " [4.00434765e-05 9.86774802e-01 5.15775127e-06 1.16784495e-05\n",
            "  1.31463157e-02 2.21293431e-05]\n",
            " [3.58260354e-06 3.07211012e-05 2.64165756e-05 9.99188006e-01\n",
            "  7.48545979e-04 2.69167276e-06]\n",
            " [2.01387593e-05 1.40725547e-06 2.66120509e-07 9.99776900e-01\n",
            "  1.96908557e-04 4.45006526e-06]\n",
            " [4.31331455e-06 4.98713553e-06 5.87032957e-07 1.41314615e-07\n",
            "  3.54080203e-06 9.99986410e-01]\n",
            " [2.54883380e-05 3.83356899e-01 1.79614403e-07 4.50099691e-08\n",
            "  6.16608799e-01 8.62754041e-06]\n",
            " [8.96838446e-06 8.54431652e-03 9.91446376e-01 2.78073458e-07\n",
            "  1.06507791e-07 2.27158665e-08]\n",
            " [4.87377292e-06 9.97351885e-01 1.35609417e-08 9.96243177e-09\n",
            "  2.63554137e-03 7.75415356e-06]\n",
            " [9.20286958e-10 9.99999881e-01 4.45551679e-10 4.85024889e-13\n",
            "  2.48387932e-09 7.64152830e-08]\n",
            " [9.99992609e-01 2.07925069e-07 2.32369519e-08 2.08293898e-08\n",
            "  5.85127646e-06 1.32428079e-06]\n",
            " [2.64458072e-06 9.99026299e-01 2.34095623e-08 1.96637835e-08\n",
            "  9.62268503e-04 8.83768553e-06]\n",
            " [6.10126990e-05 1.25897932e-05 3.63869617e-07 7.74613436e-05\n",
            "  9.99833226e-01 1.53929941e-05]\n",
            " [4.60317210e-07 1.38964877e-03 5.52908241e-05 9.98491049e-01\n",
            "  6.33345553e-05 2.33257595e-07]\n",
            " [7.22820777e-03 4.19938224e-05 1.84100458e-07 1.05844231e-06\n",
            "  7.73246882e-07 9.92727757e-01]\n",
            " [4.40217264e-05 5.26044169e-05 4.33919377e-06 4.92186291e-06\n",
            "  5.60291628e-05 9.99838114e-01]\n",
            " [1.66270729e-05 2.99356670e-05 2.38935422e-06 1.31478726e-06\n",
            "  2.01748826e-05 9.99929547e-01]\n",
            " [1.74975380e-01 8.24794114e-01 8.86528539e-09 2.27337860e-09\n",
            "  3.85100023e-08 2.30462218e-04]\n",
            " [1.52845660e-05 7.01714953e-08 4.36959965e-07 7.72126950e-05\n",
            "  9.99827206e-01 7.98802794e-05]\n",
            " [9.98557807e-05 2.53364153e-04 2.28794397e-06 1.07870364e-05\n",
            "  9.99552667e-01 8.10454148e-05]\n",
            " [1.65740366e-05 9.77714896e-01 1.16023253e-08 4.14717789e-08\n",
            "  2.22584158e-02 1.01184978e-05]\n",
            " [1.74636680e-05 2.45946723e-07 1.54384293e-06 2.51430320e-05\n",
            "  9.99858975e-01 9.66425578e-05]\n",
            " [2.63018392e-05 3.49218510e-07 4.34650076e-07 5.44854174e-07\n",
            "  3.24164539e-05 9.99939919e-01]\n",
            " [7.66117009e-05 9.49658513e-01 1.68035462e-04 1.60276191e-04\n",
            "  4.97666821e-02 1.69952982e-04]\n",
            " [4.88499863e-05 1.51089284e-06 6.11617634e-06 6.22214793e-05\n",
            "  9.99605596e-01 2.75693688e-04]\n",
            " [4.43778175e-04 9.99274075e-01 2.49886536e-04 8.14634768e-06\n",
            "  1.48190229e-05 9.36700508e-06]\n",
            " [1.18282522e-04 4.85486314e-02 5.92056289e-02 8.87793958e-01\n",
            "  4.26426437e-03 6.92273024e-05]\n",
            " [7.90141712e-05 4.94703454e-06 2.00320337e-05 2.13327265e-04\n",
            "  9.99202430e-01 4.80303221e-04]\n",
            " [9.99990940e-01 6.97125733e-06 5.26077827e-07 2.19848843e-07\n",
            "  6.56298596e-07 6.67462075e-07]\n",
            " [9.99989867e-01 5.78314314e-07 2.78110091e-09 1.74382500e-08\n",
            "  8.48666878e-06 1.07561164e-06]\n",
            " [9.89633560e-01 1.03453482e-02 1.44145997e-05 1.78487028e-06\n",
            "  1.30008084e-06 3.59844717e-06]\n",
            " [5.71394302e-02 6.00480525e-05 3.21668523e-07 1.30539911e-06\n",
            "  1.33478920e-06 9.42797542e-01]\n",
            " [2.38720222e-05 3.17051331e-07 3.82848157e-07 4.61295059e-07\n",
            "  2.48178876e-05 9.99950171e-01]\n",
            " [1.32356436e-05 1.37128566e-07 9.57512952e-07 2.36061824e-05\n",
            "  9.99893427e-01 6.86012427e-05]\n",
            " [1.31062319e-04 3.87555718e-01 4.96144814e-04 1.24542054e-03\n",
            "  6.10331774e-01 2.39913672e-04]\n",
            " [7.00333985e-05 9.57553685e-01 1.75933778e-07 7.16513398e-07\n",
            "  4.23594080e-02 1.58748135e-05]\n",
            " [1.61275509e-07 1.74036264e-04 9.99825776e-01 1.00224029e-09\n",
            "  1.29504241e-09 2.97978225e-10]\n",
            " [9.99016643e-01 6.64385443e-04 3.26707891e-06 2.77998857e-04\n",
            "  3.32181262e-05 4.51311553e-06]\n",
            " [7.74190266e-05 9.60882962e-01 2.83613599e-09 1.03013376e-08\n",
            "  3.90264913e-02 1.31731922e-05]\n",
            " [2.36458213e-08 1.63632540e-05 7.54685914e-08 9.99982953e-01\n",
            "  6.17349542e-07 4.08551237e-09]\n",
            " [7.16118229e-05 2.43716090e-06 1.00431362e-05 1.93242246e-04\n",
            "  9.99340355e-01 3.82295955e-04]\n",
            " [8.31391026e-06 5.38638645e-08 4.17316159e-07 1.21496205e-05\n",
            "  9.99937892e-01 4.10987377e-05]\n",
            " [1.75472378e-04 8.38053405e-01 1.89940169e-04 3.68233561e-03\n",
            "  1.57729521e-01 1.69379098e-04]\n",
            " [4.17234609e-04 6.76455081e-01 1.05166822e-04 4.39167983e-04\n",
            "  3.22391987e-01 1.91361149e-04]\n",
            " [3.98523916e-08 2.57539650e-04 1.82606236e-04 9.99460995e-01\n",
            "  9.86226005e-05 7.09182544e-08]\n",
            " [4.63398737e-06 7.02189652e-07 2.02537279e-07 6.05311641e-08\n",
            "  7.50887466e-06 9.99986887e-01]\n",
            " [1.60974173e-06 1.75107911e-03 1.06723033e-04 9.97991323e-01\n",
            "  1.48374165e-04 9.07620347e-07]\n",
            " [1.93065309e-04 2.53541498e-06 2.86120053e-06 3.13937335e-06\n",
            "  7.34174755e-05 9.99724925e-01]\n",
            " [8.43572070e-06 1.33658259e-05 1.12160274e-06 3.21106853e-07\n",
            "  8.84573728e-06 9.99967933e-01]\n",
            " [3.53175938e-06 9.22075851e-05 3.35685115e-08 7.95066946e-09\n",
            "  9.99902129e-01 2.02666297e-06]\n",
            " [7.34547925e-08 9.99992371e-01 2.48017634e-10 1.45547887e-07\n",
            "  1.59526579e-07 7.30709326e-06]\n",
            " [1.08520137e-04 2.21228674e-06 2.28033014e-06 1.62400295e-06\n",
            "  2.31100294e-05 9.99862194e-01]\n",
            " [9.99991179e-01 3.36123037e-07 5.45601253e-09 1.45013255e-08\n",
            "  6.84600036e-06 1.68030260e-06]\n",
            " [6.53027996e-07 9.99888420e-01 5.86165479e-05 7.85829798e-06\n",
            "  5.32277090e-06 3.90543028e-05]\n",
            " [4.60709362e-06 9.99990463e-01 2.60754348e-07 1.07576523e-06\n",
            "  8.10151278e-07 2.78716561e-06]\n",
            " [9.96128917e-01 3.62443272e-03 2.39991845e-04 3.84479199e-06\n",
            "  1.05698530e-06 1.72233172e-06]\n",
            " [2.40453137e-05 1.08718962e-06 6.31940679e-07 5.16450314e-07\n",
            "  7.06799392e-06 9.99966621e-01]\n",
            " [4.10840499e-08 9.81340927e-05 2.59347162e-05 9.99838591e-01\n",
            "  3.72605718e-05 5.02859905e-08]\n",
            " [9.99993086e-01 3.60513468e-07 8.22361468e-09 1.09217755e-08\n",
            "  5.34706896e-06 1.14916293e-06]\n",
            " [2.23849765e-05 1.55527432e-05 3.14346494e-06 2.49053642e-07\n",
            "  4.17709498e-06 9.99954462e-01]\n",
            " [3.15944104e-10 1.00000000e+00 4.01531919e-09 1.10290398e-14\n",
            "  4.41328224e-12 9.67271685e-09]\n",
            " [1.98776418e-09 9.99999523e-01 8.88422003e-10 1.87649766e-12\n",
            "  2.23404779e-08 5.33898856e-07]\n",
            " [1.01849655e-05 9.99910831e-01 6.14610035e-05 4.89261467e-08\n",
            "  2.44533362e-06 1.49900588e-05]\n",
            " [1.38838161e-07 9.99983907e-01 4.37353820e-10 9.33881861e-11\n",
            "  1.32745254e-05 2.73728233e-06]]\n",
            "Histórico\n",
            "      accuracy  false_negatives  false_positives      loss  precision  \\\n",
            "0     0.328431            162.0             61.0  1.873334   0.407767   \n",
            "1     0.764706             62.0             16.0  0.649879   0.898734   \n",
            "2     0.828431             44.0             20.0  0.481035   0.888889   \n",
            "3     0.857843             43.0             11.0  0.400922   0.936047   \n",
            "4     0.852941             37.0              9.0  0.359430   0.948864   \n",
            "...        ...              ...              ...       ...        ...   \n",
            "1495  1.000000              0.0              0.0  0.001250   1.000000   \n",
            "1496  1.000000              0.0              0.0  0.001774   1.000000   \n",
            "1497  1.000000              0.0              0.0  0.001549   1.000000   \n",
            "1498  1.000000              0.0              0.0  0.001235   1.000000   \n",
            "1499  1.000000              0.0              0.0  0.000929   1.000000   \n",
            "\n",
            "        recall  true_negatives  true_positives  learning_rate  \n",
            "0     0.205882           959.0            42.0         0.0010  \n",
            "1     0.696078          1004.0           142.0         0.0010  \n",
            "2     0.784314          1000.0           160.0         0.0010  \n",
            "3     0.789216          1009.0           161.0         0.0010  \n",
            "4     0.818627          1011.0           167.0         0.0010  \n",
            "...        ...             ...             ...            ...  \n",
            "1495  1.000000          1020.0           204.0         0.0001  \n",
            "1496  1.000000          1020.0           204.0         0.0001  \n",
            "1497  1.000000          1020.0           204.0         0.0001  \n",
            "1498  1.000000          1020.0           204.0         0.0001  \n",
            "1499  1.000000          1020.0           204.0         0.0001  \n",
            "\n",
            "[1500 rows x 9 columns]\n",
            "Temp: 0.9407051282051282\n",
            "   precision  accuracy    recall  f1_score   duration  std  specificity\n",
            "0   0.940705  0.941176  0.961594   0.94675  375.19196  0.0     0.988647\n",
            "\t\t\t\tDONE\n",
            "\t\titer 7\n",
            "\t\t\tdataset_name:  AllCandidasBload\n",
            "valor de x_train no prepare data [[1295.   843.3 1091.  ...  846.4 1120.   497.5]\n",
            " [1486.   983.3 1471.  ...  984.7 1659.   578.5]\n",
            " [1374.   927.9  561.3 ...  915.  1371.   559.5]\n",
            " ...\n",
            " [1255.   813.1 1096.  ...  815.5 1091.   472.9]\n",
            " [1571.  1023.  1555.  ... 1027.  1561.   626.2]\n",
            " [1551.  1053.  1329.  ... 1060.  1319.   621.6]]\n",
            "valor de y_train no prepare data [5. 2. 6. 1. 4. 6. 1. 6. 2. 5. 1. 6. 1. 5. 1. 1. 6. 4. 5. 6. 6. 6. 5. 4.\n",
            " 2. 3. 5. 5. 1. 2. 6. 6. 2. 1. 5. 6. 4. 4. 2. 5. 5. 4. 6. 6. 4. 6. 2. 5.\n",
            " 6. 2. 1. 6. 6. 5. 2. 6. 5. 1. 5. 5. 6. 4. 5. 4. 5. 1. 5. 2. 4. 2. 5. 5.\n",
            " 2. 2. 4. 5. 2. 5. 2. 1. 4. 6. 2. 6. 5. 3. 4. 6. 2. 1. 2. 1. 6. 4. 6. 6.\n",
            " 6. 2. 5. 2. 2. 2. 1. 2. 2. 1. 3. 6. 6. 1. 2. 5. 5. 6. 5. 2. 5. 5. 6. 6.\n",
            " 1. 4. 2. 2. 6. 1. 1. 6. 1. 1. 6. 2. 6. 6. 2. 4. 2. 6. 1. 1. 5. 5. 5. 6.\n",
            " 1. 5. 2. 1. 1. 2. 5. 2. 2. 2. 6. 3. 2. 2. 6. 6. 5. 5. 5. 1. 6. 2. 5. 4.\n",
            " 3. 6. 6. 5. 5. 4. 6. 1. 2. 6. 4. 6. 4. 2. 1. 6. 2. 4. 6. 3. 2. 2. 5. 4.\n",
            " 1. 6. 6. 3. 1. 1. 2. 1. 2. 5. 2. 4.]\n",
            "valor de y_val no prepare data [6. 1. 5. 4. 2. 2. 2. 6. 5. 2. 1. 5. 1. 1. 5. 2. 6. 4. 2. 4. 6. 5. 2. 5.\n",
            " 4. 4. 6. 5. 2. 5. 2. 2. 6. 5. 2. 2. 1. 3. 5. 2. 6. 5. 1. 4. 6. 4. 5. 4.\n",
            " 4. 2. 2. 2. 4. 6. 6. 5. 2. 6. 1. 1. 2. 2. 5. 6. 3. 2. 6. 2.]\n",
            "output_directory: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_7/AllCandidasBload/\n",
            "Dentro do FitModel\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
            "Classes before: [4 1 5 0 3 5 0 5 1 4 0 5 0 4 0 0 5 3 4 5 5 5 4 3 1 2 4 4 0 1 5 5 1 0 4 5 3\n",
            " 3 1 4 4 3 5 5 3 5 1 4 5 1 0 5 5 4 1 5 4 0 4 4 5 3 4 3 4 0 4 1 3 1 4 4 1 1\n",
            " 3 4 1 4 1 0 3 5 1 5 4 2 3 5 1 0 1 0 5 3 5 5 5 1 4 1 1 1 0 1 1 0 2 5 5 0 1\n",
            " 4 4 5 4 1 4 4 5 5 0 3 1 1 5 0 0 5 0 0 5 1 5 5 1 3 1 5 0 0 4 4 4 5 0 4 1 0\n",
            " 0 1 4 1 1 1 5 2 1 1 5 5 4 4 4 0 5 1 4 3 2 5 5 4 4 3 5 0 1 5 3 5 3 1 0 5 1\n",
            " 3 5 2 1 1 4 3 0 5 5 2 0 0 1 0 1 4 1 3]\n",
            "Classes after: [0 1 2 3 4 5]\n",
            "Y_pred: [5 4 5 1 0 5 1 3 3 5 1 2 1 1 0 1 4 3 5 5 5 0 4 4 1 4 5 1 4 1 3 4 0 0 0 5 5\n",
            " 4 1 1 2 0 1 3 4 4 1 1 3 5 3 5 5 4 1 5 0 1 1 0 5 3 0 5 1 1 1 1]\n",
            "y_val [5 4 5 1 0 5 1 3 3 5 1 2 1 1 0 1 1 3 5 5 5 1 4 4 1 4 5 1 4 1 0 4 0 0 0 5 5\n",
            " 4 1 1 2 0 1 3 4 4 1 1 3 5 3 5 5 4 1 5 0 1 1 0 5 3 0 5 1 1 1 1]\n",
            "y_pred before save =  \n",
            " [[2.80196837e-04 3.16659243e-05 1.98931207e-06 1.26773848e-05\n",
            "  5.08576204e-06 9.99668360e-01]\n",
            " [4.28755338e-05 9.72529051e-07 1.08248660e-05 2.02602023e-04\n",
            "  9.99509692e-01 2.33001454e-04]\n",
            " [4.72309830e-06 3.00625834e-06 7.29109173e-09 6.84137262e-08\n",
            "  4.31972147e-09 9.99992132e-01]\n",
            " [6.47033937e-03 9.92938876e-01 2.07893407e-07 2.10654878e-04\n",
            "  9.08658330e-06 3.70688387e-04]\n",
            " [9.99994993e-01 4.01883017e-06 6.20124974e-09 1.67651933e-07\n",
            "  7.69753257e-08 6.68229688e-07]\n",
            " [1.29344244e-05 6.31260855e-06 7.41037638e-07 2.48362494e-06\n",
            "  1.86763191e-05 9.99958873e-01]\n",
            " [9.21412138e-05 9.98625278e-01 3.22768960e-06 1.87010592e-04\n",
            "  1.08575053e-03 6.64261279e-06]\n",
            " [7.24084384e-06 1.92760763e-05 4.84925040e-05 9.99478281e-01\n",
            "  4.44178411e-04 2.47225080e-06]\n",
            " [2.45153387e-05 8.52913104e-07 1.45014315e-06 9.99757111e-01\n",
            "  2.13006468e-04 3.12721113e-06]\n",
            " [4.68896314e-06 3.84777422e-06 4.02023915e-07 4.34085820e-07\n",
            "  3.09139887e-06 9.99987483e-01]\n",
            " [1.95031200e-04 9.67279077e-01 3.58783632e-06 9.04328699e-05\n",
            "  3.24251354e-02 6.85438863e-06]\n",
            " [1.75305828e-03 5.01921102e-02 9.48008537e-01 3.56350392e-05\n",
            "  9.39235724e-06 1.36327299e-06]\n",
            " [4.52045788e-06 9.99512672e-01 5.31658316e-07 1.49757966e-06\n",
            "  4.78794274e-04 1.97609847e-06]\n",
            " [1.57663109e-08 9.99998927e-01 4.89019953e-08 2.75174176e-12\n",
            "  5.98157257e-08 9.66118364e-07]\n",
            " [9.99995470e-01 1.94485210e-06 8.83058888e-08 8.25563546e-08\n",
            "  1.80149243e-06 6.26086091e-07]\n",
            " [5.88640069e-06 9.99393582e-01 8.32349826e-07 1.23302857e-06\n",
            "  5.89493720e-04 9.02953798e-06]\n",
            " [3.25577275e-04 1.22285492e-04 1.04134793e-04 4.89033060e-04\n",
            "  9.98907924e-01 5.10917671e-05]\n",
            " [9.48986042e-07 2.79062457e-04 2.20013062e-05 9.99678135e-01\n",
            "  1.97995414e-05 1.29808328e-07]\n",
            " [1.04767218e-01 7.69045716e-03 1.41948340e-06 4.94873666e-06\n",
            "  1.99316673e-06 8.87533963e-01]\n",
            " [4.30334476e-05 1.07125212e-04 3.37123129e-06 1.38334290e-05\n",
            "  3.99133460e-05 9.99792755e-01]\n",
            " [2.10285652e-05 5.97907165e-05 2.30929913e-06 4.20582137e-06\n",
            "  1.88004597e-05 9.99893904e-01]\n",
            " [6.10082030e-01 3.89681727e-01 8.54524229e-10 3.22809612e-10\n",
            "  2.61934066e-08 2.36225213e-04]\n",
            " [3.47248788e-05 3.95617462e-07 5.30401621e-06 1.84169083e-04\n",
            "  9.99623179e-01 1.52221663e-04]\n",
            " [4.05571947e-04 1.25014223e-03 1.04640436e-04 1.15404226e-04\n",
            "  9.97980654e-01 1.43573168e-04]\n",
            " [1.36632007e-05 9.96539712e-01 3.28704402e-07 4.10090342e-06\n",
            "  3.43667995e-03 5.44457862e-06]\n",
            " [2.99614894e-05 8.42353529e-07 7.29397880e-06 2.60685083e-05\n",
            "  9.99809563e-01 1.26371844e-04]\n",
            " [6.84190454e-05 9.82640177e-06 4.57577562e-06 4.76237119e-06\n",
            "  1.00659585e-04 9.99811828e-01]\n",
            " [2.30720339e-04 9.90534604e-01 1.24409096e-04 2.45967694e-03\n",
            "  6.60869479e-03 4.18322561e-05]\n",
            " [6.52578019e-05 3.33991375e-06 1.84719611e-05 4.50011175e-05\n",
            "  9.99584377e-01 2.83604051e-04]\n",
            " [4.41745942e-04 9.99514818e-01 1.74680481e-05 6.93241782e-06\n",
            "  3.69670056e-06 1.53465735e-05]\n",
            " [1.46619626e-04 5.51332440e-03 1.01144619e-01 8.84830654e-01\n",
            "  8.33796989e-03 2.68379754e-05]\n",
            " [9.32232942e-05 5.94170660e-06 3.23423992e-05 1.49964486e-04\n",
            "  9.99319196e-01 3.99333629e-04]\n",
            " [9.99768555e-01 1.80339543e-04 5.26389385e-07 2.25964577e-05\n",
            "  9.09456901e-07 2.70339224e-05]\n",
            " [9.99995589e-01 3.31296246e-06 1.10806626e-08 1.65429611e-07\n",
            "  4.23949160e-07 4.21075811e-07]\n",
            " [9.99967933e-01 3.19565625e-05 7.20920781e-08 5.06066655e-08\n",
            "  1.35946703e-08 1.40803040e-08]\n",
            " [3.69772881e-01 2.99836998e-03 1.53930671e-06 4.01693660e-06\n",
            "  1.88720685e-06 6.27221346e-01]\n",
            " [6.27889167e-05 9.11389543e-06 3.87873160e-06 3.98694237e-06\n",
            "  7.50700565e-05 9.99845147e-01]\n",
            " [2.50978846e-05 5.78327672e-07 5.96510836e-06 3.32699092e-05\n",
            "  9.99826133e-01 1.08924731e-04]\n",
            " [5.62315166e-04 8.77891779e-01 1.35785737e-03 3.60824205e-02\n",
            "  8.39905068e-02 1.15147028e-04]\n",
            " [6.25469766e-05 9.99308348e-01 1.62621077e-07 2.81641060e-05\n",
            "  5.98911196e-04 1.89585637e-06]\n",
            " [4.90780039e-05 2.32472573e-03 9.97625768e-01 3.36892469e-07\n",
            "  1.53326482e-07 1.97585805e-08]\n",
            " [9.99817550e-01 1.02260936e-04 2.06073150e-06 7.40587420e-05\n",
            "  4.09826953e-06 1.64096264e-07]\n",
            " [1.24863782e-05 9.99585569e-01 4.39003900e-09 6.05438117e-08\n",
            "  3.99647019e-04 2.09572340e-06]\n",
            " [3.74669327e-08 5.68849464e-06 6.23054575e-07 9.99992967e-01\n",
            "  7.05977584e-07 1.23757959e-09]\n",
            " [9.21617175e-05 4.17626825e-06 2.45336614e-05 1.66329410e-04\n",
            "  9.99339998e-01 3.72813287e-04]\n",
            " [1.75841360e-05 3.15564733e-07 3.72137447e-06 1.78244263e-05\n",
            "  9.99886155e-01 7.43452038e-05]\n",
            " [3.65092419e-04 9.41658556e-01 2.06170633e-04 4.83902059e-02\n",
            "  9.34232492e-03 3.76314529e-05]\n",
            " [7.22675934e-04 9.80700374e-01 8.71556040e-05 2.07727822e-03\n",
            "  1.63430888e-02 6.92928807e-05]\n",
            " [1.16432901e-07 9.32879848e-05 1.26829429e-04 9.99759972e-01\n",
            "  1.97725767e-05 2.16172893e-08]\n",
            " [9.07578215e-06 2.04229559e-06 6.01095564e-07 3.59748526e-07\n",
            "  1.22658157e-05 9.99975681e-01]\n",
            " [3.01038835e-06 3.02001572e-04 3.58277612e-05 9.99607503e-01\n",
            "  5.12137776e-05 4.58928895e-07]\n",
            " [4.21530363e-04 3.84215891e-05 1.17397904e-05 2.73031746e-05\n",
            "  1.44420148e-04 9.99356568e-01]\n",
            " [1.42382623e-05 2.07426237e-05 1.51013990e-06 1.45175011e-06\n",
            "  1.11000163e-05 9.99951005e-01]\n",
            " [1.29556611e-05 2.45874602e-04 5.07295817e-06 3.68674165e-07\n",
            "  9.99732077e-01 3.72250474e-06]\n",
            " [4.03163767e-07 9.99990225e-01 3.19353821e-10 1.64225597e-07\n",
            "  5.63619622e-08 9.34225045e-06]\n",
            " [2.31464524e-04 2.81143202e-05 9.54184634e-06 1.53217006e-05\n",
            "  6.80219528e-05 9.99647498e-01]\n",
            " [9.99993324e-01 4.74319495e-06 1.08758975e-08 2.27261609e-07\n",
            "  2.35680460e-07 1.45649324e-06]\n",
            " [3.69585759e-05 9.98272061e-01 8.70058837e-04 6.55328971e-04\n",
            "  9.81088015e-05 6.74546609e-05]\n",
            " [9.82039637e-06 9.99964356e-01 8.58781050e-07 2.10584858e-05\n",
            "  6.84718486e-07 3.16443675e-06]\n",
            " [9.99973416e-01 2.61142868e-05 4.06490301e-07 1.58396290e-07\n",
            "  1.40657246e-08 6.40963727e-09]\n",
            " [8.01848582e-05 2.78703010e-05 3.73697549e-06 8.68870393e-06\n",
            "  2.31126960e-05 9.99856353e-01]\n",
            " [1.14465600e-07 3.35807053e-05 2.56617441e-05 9.99928117e-01\n",
            "  1.25190400e-05 1.93431298e-08]\n",
            " [9.99992132e-01 6.17095338e-06 1.40144643e-08 2.32923327e-07\n",
            "  2.81497165e-07 1.13372300e-06]\n",
            " [7.00860110e-05 5.75073682e-05 1.08445538e-05 2.78433890e-06\n",
            "  3.13477831e-05 9.99827385e-01]\n",
            " [1.52273270e-08 9.99999285e-01 4.15918151e-07 5.73389467e-14\n",
            "  2.19058927e-09 2.98713871e-07]\n",
            " [8.55618936e-08 9.99995232e-01 2.20804566e-07 6.82415444e-11\n",
            "  4.27935930e-07 3.91013145e-06]\n",
            " [8.93293764e-05 9.99508977e-01 3.77151533e-04 1.16515571e-06\n",
            "  4.32668048e-06 1.90577048e-05]\n",
            " [2.83486912e-07 9.99974728e-01 1.36962921e-08 2.98337688e-10\n",
            "  1.54884183e-05 9.57877273e-06]]\n",
            "Histórico\n",
            "      accuracy  false_negatives  false_positives      loss  precision  \\\n",
            "0     0.485294            123.0             45.0  1.347392   0.642857   \n",
            "1     0.794118             59.0             19.0  0.507199   0.884146   \n",
            "2     0.808824             51.0             24.0  0.445070   0.864407   \n",
            "3     0.828431             44.0             21.0  0.433594   0.883978   \n",
            "4     0.852941             50.0             10.0  0.430108   0.939024   \n",
            "...        ...              ...              ...       ...        ...   \n",
            "1495  1.000000              0.0              0.0  0.002035   1.000000   \n",
            "1496  1.000000              0.0              0.0  0.003584   1.000000   \n",
            "1497  0.995098              1.0              1.0  0.006590   0.995098   \n",
            "1498  1.000000              0.0              0.0  0.004537   1.000000   \n",
            "1499  1.000000              0.0              0.0  0.002855   1.000000   \n",
            "\n",
            "        recall  true_negatives  true_positives  learning_rate  \n",
            "0     0.397059           975.0            81.0         0.0010  \n",
            "1     0.710784          1001.0           145.0         0.0010  \n",
            "2     0.750000           996.0           153.0         0.0010  \n",
            "3     0.784314           999.0           160.0         0.0010  \n",
            "4     0.754902          1010.0           154.0         0.0010  \n",
            "...        ...             ...             ...            ...  \n",
            "1495  1.000000          1020.0           204.0         0.0001  \n",
            "1496  1.000000          1020.0           204.0         0.0001  \n",
            "1497  0.995098          1019.0           203.0         0.0001  \n",
            "1498  1.000000          1020.0           204.0         0.0001  \n",
            "1499  1.000000          1020.0           204.0         0.0001  \n",
            "\n",
            "[1500 rows x 9 columns]\n",
            "Temp: 0.9473484848484848\n",
            "   precision  accuracy    recall  f1_score    duration  std  specificity\n",
            "0   0.947348  0.955882  0.968841   0.95671  367.028566  0.0     0.991521\n",
            "\t\t\t\tDONE\n",
            "\t\titer 8\n",
            "\t\t\tdataset_name:  AllCandidasBload\n",
            "valor de x_train no prepare data [[1295.   843.3 1091.  ...  846.4 1120.   497.5]\n",
            " [1486.   983.3 1471.  ...  984.7 1659.   578.5]\n",
            " [1374.   927.9  561.3 ...  915.  1371.   559.5]\n",
            " ...\n",
            " [1255.   813.1 1096.  ...  815.5 1091.   472.9]\n",
            " [1571.  1023.  1555.  ... 1027.  1561.   626.2]\n",
            " [1551.  1053.  1329.  ... 1060.  1319.   621.6]]\n",
            "valor de y_train no prepare data [5. 2. 6. 1. 4. 6. 1. 6. 2. 5. 1. 6. 1. 5. 1. 1. 6. 4. 5. 6. 6. 6. 5. 4.\n",
            " 2. 3. 5. 5. 1. 2. 6. 6. 2. 1. 5. 6. 4. 4. 2. 5. 5. 4. 6. 6. 4. 6. 2. 5.\n",
            " 6. 2. 1. 6. 6. 5. 2. 6. 5. 1. 5. 5. 6. 4. 5. 4. 5. 1. 5. 2. 4. 2. 5. 5.\n",
            " 2. 2. 4. 5. 2. 5. 2. 1. 4. 6. 2. 6. 5. 3. 4. 6. 2. 1. 2. 1. 6. 4. 6. 6.\n",
            " 6. 2. 5. 2. 2. 2. 1. 2. 2. 1. 3. 6. 6. 1. 2. 5. 5. 6. 5. 2. 5. 5. 6. 6.\n",
            " 1. 4. 2. 2. 6. 1. 1. 6. 1. 1. 6. 2. 6. 6. 2. 4. 2. 6. 1. 1. 5. 5. 5. 6.\n",
            " 1. 5. 2. 1. 1. 2. 5. 2. 2. 2. 6. 3. 2. 2. 6. 6. 5. 5. 5. 1. 6. 2. 5. 4.\n",
            " 3. 6. 6. 5. 5. 4. 6. 1. 2. 6. 4. 6. 4. 2. 1. 6. 2. 4. 6. 3. 2. 2. 5. 4.\n",
            " 1. 6. 6. 3. 1. 1. 2. 1. 2. 5. 2. 4.]\n",
            "valor de y_val no prepare data [6. 1. 5. 4. 2. 2. 2. 6. 5. 2. 1. 5. 1. 1. 5. 2. 6. 4. 2. 4. 6. 5. 2. 5.\n",
            " 4. 4. 6. 5. 2. 5. 2. 2. 6. 5. 2. 2. 1. 3. 5. 2. 6. 5. 1. 4. 6. 4. 5. 4.\n",
            " 4. 2. 2. 2. 4. 6. 6. 5. 2. 6. 1. 1. 2. 2. 5. 6. 3. 2. 6. 2.]\n",
            "output_directory: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_8/AllCandidasBload/\n",
            "Dentro do FitModel\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 878ms/step\n",
            "Classes before: [4 1 5 0 3 5 0 5 1 4 0 5 0 4 0 0 5 3 4 5 5 5 4 3 1 2 4 4 0 1 5 5 1 0 4 5 3\n",
            " 3 1 4 4 3 5 5 3 5 1 4 5 1 0 5 5 4 1 5 4 0 4 4 5 3 4 3 4 0 4 1 3 1 4 4 1 1\n",
            " 3 4 1 4 1 0 3 5 1 5 4 2 3 5 1 0 1 0 5 3 5 5 5 1 4 1 1 1 0 1 1 0 2 5 5 0 1\n",
            " 4 4 5 4 1 4 4 5 5 0 3 1 1 5 0 0 5 0 0 5 1 5 5 1 3 1 5 0 0 4 4 4 5 0 4 1 0\n",
            " 0 1 4 1 1 1 5 2 1 1 5 5 4 4 4 0 5 1 4 3 2 5 5 4 4 3 5 0 1 5 3 5 3 1 0 5 1\n",
            " 3 5 2 1 1 4 3 0 5 5 2 0 0 1 0 1 4 1 3]\n",
            "Classes after: [0 1 2 3 4 5]\n",
            "Y_pred: [5 4 5 1 0 5 1 3 3 5 1 2 1 1 0 1 4 3 5 5 5 1 4 4 1 4 5 1 4 1 3 4 0 0 0 5 5\n",
            " 4 4 1 2 0 1 3 4 4 1 1 3 5 3 5 5 4 1 5 0 1 1 0 5 3 0 5 1 1 1 1]\n",
            "y_val [5 4 5 1 0 5 1 3 3 5 1 2 1 1 0 1 1 3 5 5 5 1 4 4 1 4 5 1 4 1 0 4 0 0 0 5 5\n",
            " 4 1 1 2 0 1 3 4 4 1 1 3 5 3 5 5 4 1 5 0 1 1 0 5 3 0 5 1 1 1 1]\n",
            "y_pred before save =  \n",
            " [[9.11044572e-06 5.89438223e-08 1.13110566e-07 3.96589058e-07\n",
            "  6.60323280e-08 9.99990225e-01]\n",
            " [1.72349610e-05 1.38598182e-07 1.96224082e-05 5.38779350e-05\n",
            "  9.99792278e-01 1.16970958e-04]\n",
            " [9.32282163e-08 4.59192240e-09 3.37427808e-10 2.49662291e-09\n",
            "  5.73994637e-11 9.99999881e-01]\n",
            " [1.52814096e-06 9.99434412e-01 2.88967588e-08 7.41712392e-06\n",
            "  4.29545004e-08 5.56678977e-04]\n",
            " [9.99917626e-01 1.11585505e-05 4.35494876e-08 2.39118009e-07\n",
            "  4.19259123e-07 7.04760751e-05]\n",
            " [3.95317556e-06 7.20823891e-07 6.50625088e-06 4.75077115e-07\n",
            "  1.40915363e-05 9.99974251e-01]\n",
            " [3.26523036e-06 9.98295367e-01 1.05400466e-06 1.74097895e-05\n",
            "  1.68171315e-03 1.27147655e-06]\n",
            " [7.63476010e-07 8.46973762e-06 4.26992119e-06 9.99917269e-01\n",
            "  6.87659121e-05 5.12244185e-07]\n",
            " [5.14304411e-05 2.08058193e-08 6.55874022e-09 9.99871254e-01\n",
            "  7.42163684e-05 2.92032564e-06]\n",
            " [4.17136334e-07 2.97986560e-07 1.51934819e-06 3.57424810e-08\n",
            "  5.99349960e-07 9.99997139e-01]\n",
            " [3.37242227e-07 9.81714129e-01 3.27744836e-08 3.73563040e-07\n",
            "  1.82849895e-02 7.26076337e-08]\n",
            " [7.81306735e-05 3.48097801e-01 6.51819646e-01 8.50872652e-07\n",
            "  4.04065403e-08 3.47146579e-06]\n",
            " [1.38072369e-06 9.99987483e-01 2.48279353e-08 8.44618420e-09\n",
            "  1.01400956e-05 9.88634042e-07]\n",
            " [3.70912294e-11 9.99998569e-01 5.49939028e-09 1.87591209e-16\n",
            "  1.80906082e-12 1.43178693e-06]\n",
            " [9.99733388e-01 1.07689530e-05 2.75041486e-07 1.93701069e-07\n",
            "  1.55783964e-05 2.39829955e-04]\n",
            " [5.82688529e-07 9.99987245e-01 1.12890717e-07 9.38138456e-09\n",
            "  7.69340750e-06 4.26342831e-06]\n",
            " [4.77814137e-05 3.29228919e-06 1.09372638e-06 7.94818625e-04\n",
            "  9.99077916e-01 7.50796607e-05]\n",
            " [8.27625257e-08 4.93876578e-04 1.68837096e-06 9.99500990e-01\n",
            "  3.28356577e-06 1.44991104e-08]\n",
            " [2.12926670e-06 4.08299593e-06 4.63965488e-09 1.66802749e-08\n",
            "  4.79643603e-10 9.99993801e-01]\n",
            " [1.23849459e-05 1.38308014e-05 1.35903383e-05 2.09239056e-06\n",
            "  1.57701343e-05 9.99942303e-01]\n",
            " [2.18556079e-06 3.62330138e-06 5.74249634e-06 3.33266598e-07\n",
            "  2.55341092e-06 9.99985576e-01]\n",
            " [3.37529927e-02 9.14350986e-01 1.32544319e-05 4.21779633e-09\n",
            "  3.03680778e-08 5.18827103e-02]\n",
            " [1.36382296e-05 2.12105569e-08 4.58526165e-06 2.72744965e-05\n",
            "  9.99892354e-01 6.21431900e-05]\n",
            " [8.55724284e-06 1.84970733e-04 2.33667311e-06 1.96830206e-05\n",
            "  9.99754131e-01 3.02420704e-05]\n",
            " [6.84581892e-06 9.99923706e-01 2.79382650e-08 8.40294092e-08\n",
            "  6.64783511e-05 2.88086585e-06]\n",
            " [7.08656034e-06 3.72746456e-09 1.01106684e-06 2.12328928e-06\n",
            "  9.99963641e-01 2.60551496e-05]\n",
            " [3.68181122e-06 2.32735200e-08 5.81544555e-07 3.97022461e-07\n",
            "  3.83095767e-06 9.99991536e-01]\n",
            " [2.49138679e-06 9.86184895e-01 6.57614510e-05 8.15252570e-05\n",
            "  1.36603164e-02 5.16746013e-06]\n",
            " [1.38283358e-05 1.86989535e-08 2.58333148e-06 3.63185200e-06\n",
            "  9.99917507e-01 6.24889726e-05]\n",
            " [5.33304592e-05 9.99801338e-01 1.14613125e-04 2.71734098e-05\n",
            "  4.26646068e-07 3.12831298e-06]\n",
            " [3.29907016e-06 8.99558887e-04 1.74743718e-06 9.98862028e-01\n",
            "  2.32469931e-04 8.96601875e-07]\n",
            " [1.85745448e-05 2.90350442e-07 2.09571626e-05 2.00269333e-05\n",
            "  9.99790490e-01 1.49656247e-04]\n",
            " [9.99401093e-01 4.42549703e-04 5.64484662e-06 3.39940379e-06\n",
            "  5.68421399e-07 1.46704610e-04]\n",
            " [9.99925375e-01 1.69892485e-06 3.10333768e-08 2.02709955e-07\n",
            "  1.45303977e-06 7.13294721e-05]\n",
            " [9.77828741e-01 2.02417150e-02 6.38778962e-04 4.57805436e-05\n",
            "  8.98910639e-06 1.23593863e-03]\n",
            " [4.97673545e-06 8.34867535e-07 3.26995853e-09 6.77723744e-09\n",
            "  1.99528130e-10 9.99994159e-01]\n",
            " [3.18245134e-06 1.75612094e-08 4.18284088e-07 3.05913147e-07\n",
            "  2.62020080e-06 9.99993443e-01]\n",
            " [7.27925271e-06 3.57857499e-09 1.11175609e-06 2.93431253e-06\n",
            "  9.99963880e-01 2.48361030e-05]\n",
            " [2.25326967e-05 4.03204948e-01 6.47258072e-04 2.87853694e-03\n",
            "  5.93201995e-01 4.47519560e-05]\n",
            " [1.97461009e-06 9.99635696e-01 1.57394968e-08 8.13680458e-07\n",
            "  3.61240760e-04 1.91237191e-07]\n",
            " [4.51934011e-06 3.47248255e-03 9.96522903e-01 2.71658918e-09\n",
            "  2.38668263e-09 1.72518568e-07]\n",
            " [9.86593068e-01 8.22145585e-03 3.83887564e-05 3.93599086e-03\n",
            "  5.84583497e-04 6.26688241e-04]\n",
            " [1.06903610e-06 9.99986053e-01 8.28621727e-10 1.23693378e-09\n",
            "  1.10858482e-05 1.81916630e-06]\n",
            " [9.27673085e-08 4.07017033e-05 7.23873868e-08 9.99958873e-01\n",
            "  2.80193632e-07 5.95932947e-09]\n",
            " [1.56854039e-05 1.46725739e-07 1.10905112e-05 1.61393709e-05\n",
            "  9.99838233e-01 1.18691256e-04]\n",
            " [4.63823790e-06 5.82681459e-10 3.40007887e-07 1.08814550e-06\n",
            "  9.99982476e-01 1.14949771e-05]\n",
            " [1.25396749e-04 7.81084299e-01 1.25565013e-04 5.69467153e-03\n",
            "  2.12926790e-01 4.32105007e-05]\n",
            " [9.55632713e-05 9.74869549e-01 1.90496903e-05 1.50465127e-03\n",
            "  2.34790016e-02 3.23442546e-05]\n",
            " [5.37156231e-09 3.98186057e-05 1.06281659e-05 9.99944329e-01\n",
            "  5.23568633e-06 3.62190278e-09]\n",
            " [2.56189793e-07 2.83324422e-08 2.50220324e-07 1.10868523e-08\n",
            "  5.13905661e-07 9.99998927e-01]\n",
            " [2.18585726e-07 5.55540726e-04 2.97882889e-06 9.99433339e-01\n",
            "  7.83300493e-06 5.21179437e-08]\n",
            " [1.68325932e-05 2.60486843e-07 1.53805354e-06 9.35717196e-07\n",
            "  3.51841095e-06 9.99976873e-01]\n",
            " [5.54992937e-07 8.77405171e-07 1.91062600e-06 5.51742900e-08\n",
            "  6.34488288e-07 9.99995947e-01]\n",
            " [5.29165796e-08 2.18673478e-04 6.59241124e-08 6.70282105e-08\n",
            "  9.99780595e-01 5.58555826e-07]\n",
            " [1.81320092e-09 9.99963641e-01 1.43038781e-09 6.96420912e-08\n",
            "  2.67748446e-09 3.62416758e-05]\n",
            " [8.30607678e-06 2.11238074e-07 1.11740883e-06 6.06804861e-07\n",
            "  9.62669787e-07 9.99988794e-01]\n",
            " [9.99889851e-01 4.30363752e-06 4.15617443e-08 2.62868781e-07\n",
            "  5.93720472e-07 1.04956263e-04]\n",
            " [4.61848640e-06 9.93460894e-01 6.15154626e-03 3.94119452e-05\n",
            "  4.51719316e-05 2.98355473e-04]\n",
            " [1.15145131e-05 9.99924779e-01 3.98269719e-07 7.96549375e-06\n",
            "  3.63948033e-07 5.49899596e-05]\n",
            " [7.28121459e-01 2.56045938e-01 1.34004084e-02 1.46811712e-04\n",
            "  2.04779935e-05 2.26492248e-03]\n",
            " [3.35518280e-06 7.96302402e-08 4.51560879e-07 3.18114473e-07\n",
            "  5.24325060e-07 9.99995232e-01]\n",
            " [7.83895437e-09 2.03445052e-05 2.61323908e-06 9.99974608e-01\n",
            "  2.40365489e-06 3.65547170e-09]\n",
            " [9.99931335e-01 7.53132781e-06 6.03530452e-08 2.08129549e-07\n",
            "  5.09862730e-07 6.02947985e-05]\n",
            " [4.06404837e-07 3.05482445e-07 1.25201211e-06 1.60349050e-08\n",
            "  1.65138388e-07 9.99997854e-01]\n",
            " [1.64393169e-11 9.99999404e-01 3.76306772e-08 2.91571550e-19\n",
            "  3.76709907e-14 6.18511194e-07]\n",
            " [7.45314743e-09 9.99981642e-01 1.61210849e-07 1.84596953e-13\n",
            "  1.81236215e-09 1.82333988e-05]\n",
            " [2.00288255e-07 9.99984145e-01 6.97446239e-06 2.96335312e-09\n",
            "  8.88910545e-09 8.63683726e-06]\n",
            " [1.93353795e-08 9.99960303e-01 6.77180090e-09 2.79226620e-12\n",
            "  1.24187158e-08 3.96505675e-05]]\n",
            "Histórico\n",
            "      accuracy  false_negatives  false_positives      loss  precision  \\\n",
            "0     0.460784            152.0             24.0  1.386673   0.684211   \n",
            "1     0.803922             54.0             28.0  0.616691   0.842697   \n",
            "2     0.848039             59.0             12.0  0.449024   0.923567   \n",
            "3     0.848039             44.0             23.0  0.403555   0.874317   \n",
            "4     0.862745             45.0             15.0  0.396475   0.913793   \n",
            "...        ...              ...              ...       ...        ...   \n",
            "1495  1.000000              0.0              0.0  0.003444   1.000000   \n",
            "1496  1.000000              0.0              0.0  0.002726   1.000000   \n",
            "1497  1.000000              0.0              0.0  0.001999   1.000000   \n",
            "1498  1.000000              0.0              0.0  0.002156   1.000000   \n",
            "1499  1.000000              0.0              0.0  0.001752   1.000000   \n",
            "\n",
            "        recall  true_negatives  true_positives  learning_rate  \n",
            "0     0.254902           996.0            52.0         0.0010  \n",
            "1     0.735294           992.0           150.0         0.0010  \n",
            "2     0.710784          1008.0           145.0         0.0010  \n",
            "3     0.784314           997.0           160.0         0.0010  \n",
            "4     0.779412          1005.0           159.0         0.0010  \n",
            "...        ...             ...             ...            ...  \n",
            "1495  1.000000          1020.0           204.0         0.0001  \n",
            "1496  1.000000          1020.0           204.0         0.0001  \n",
            "1497  1.000000          1020.0           204.0         0.0001  \n",
            "1498  1.000000          1020.0           204.0         0.0001  \n",
            "1499  1.000000          1020.0           204.0         0.0001  \n",
            "\n",
            "[1500 rows x 9 columns]\n",
            "Temp: 0.9513888888888888\n",
            "   precision  accuracy    recall  f1_score    duration  std  specificity\n",
            "0   0.951389  0.955882  0.968841   0.95739  372.721217  0.0     0.991521\n",
            "\t\t\t\tDONE\n",
            "\t\titer 9\n",
            "\t\t\tdataset_name:  AllCandidasBload\n",
            "valor de x_train no prepare data [[1295.   843.3 1091.  ...  846.4 1120.   497.5]\n",
            " [1486.   983.3 1471.  ...  984.7 1659.   578.5]\n",
            " [1374.   927.9  561.3 ...  915.  1371.   559.5]\n",
            " ...\n",
            " [1255.   813.1 1096.  ...  815.5 1091.   472.9]\n",
            " [1571.  1023.  1555.  ... 1027.  1561.   626.2]\n",
            " [1551.  1053.  1329.  ... 1060.  1319.   621.6]]\n",
            "valor de y_train no prepare data [5. 2. 6. 1. 4. 6. 1. 6. 2. 5. 1. 6. 1. 5. 1. 1. 6. 4. 5. 6. 6. 6. 5. 4.\n",
            " 2. 3. 5. 5. 1. 2. 6. 6. 2. 1. 5. 6. 4. 4. 2. 5. 5. 4. 6. 6. 4. 6. 2. 5.\n",
            " 6. 2. 1. 6. 6. 5. 2. 6. 5. 1. 5. 5. 6. 4. 5. 4. 5. 1. 5. 2. 4. 2. 5. 5.\n",
            " 2. 2. 4. 5. 2. 5. 2. 1. 4. 6. 2. 6. 5. 3. 4. 6. 2. 1. 2. 1. 6. 4. 6. 6.\n",
            " 6. 2. 5. 2. 2. 2. 1. 2. 2. 1. 3. 6. 6. 1. 2. 5. 5. 6. 5. 2. 5. 5. 6. 6.\n",
            " 1. 4. 2. 2. 6. 1. 1. 6. 1. 1. 6. 2. 6. 6. 2. 4. 2. 6. 1. 1. 5. 5. 5. 6.\n",
            " 1. 5. 2. 1. 1. 2. 5. 2. 2. 2. 6. 3. 2. 2. 6. 6. 5. 5. 5. 1. 6. 2. 5. 4.\n",
            " 3. 6. 6. 5. 5. 4. 6. 1. 2. 6. 4. 6. 4. 2. 1. 6. 2. 4. 6. 3. 2. 2. 5. 4.\n",
            " 1. 6. 6. 3. 1. 1. 2. 1. 2. 5. 2. 4.]\n",
            "valor de y_val no prepare data [6. 1. 5. 4. 2. 2. 2. 6. 5. 2. 1. 5. 1. 1. 5. 2. 6. 4. 2. 4. 6. 5. 2. 5.\n",
            " 4. 4. 6. 5. 2. 5. 2. 2. 6. 5. 2. 2. 1. 3. 5. 2. 6. 5. 1. 4. 6. 4. 5. 4.\n",
            " 4. 2. 2. 2. 4. 6. 6. 5. 2. 6. 1. 1. 2. 2. 5. 6. 3. 2. 6. 2.]\n",
            "output_directory: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_9/AllCandidasBload/\n",
            "Dentro do FitModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 908ms/step\n",
            "Classes before: [4 1 5 0 3 5 0 5 1 4 0 5 0 4 0 0 5 3 4 5 5 5 4 3 1 2 4 4 0 1 5 5 1 0 4 5 3\n",
            " 3 1 4 4 3 5 5 3 5 1 4 5 1 0 5 5 4 1 5 4 0 4 4 5 3 4 3 4 0 4 1 3 1 4 4 1 1\n",
            " 3 4 1 4 1 0 3 5 1 5 4 2 3 5 1 0 1 0 5 3 5 5 5 1 4 1 1 1 0 1 1 0 2 5 5 0 1\n",
            " 4 4 5 4 1 4 4 5 5 0 3 1 1 5 0 0 5 0 0 5 1 5 5 1 3 1 5 0 0 4 4 4 5 0 4 1 0\n",
            " 0 1 4 1 1 1 5 2 1 1 5 5 4 4 4 0 5 1 4 3 2 5 5 4 4 3 5 0 1 5 3 5 3 1 0 5 1\n",
            " 3 5 2 1 1 4 3 0 5 5 2 0 0 1 0 1 4 1 3]\n",
            "Classes after: [0 1 2 3 4 5]\n",
            "Y_pred: [5 4 5 1 0 5 1 3 3 5 1 1 1 1 0 1 4 3 5 5 5 1 4 4 1 4 5 1 4 1 3 4 0 0 0 5 5\n",
            " 4 1 1 2 0 1 3 4 4 1 1 3 5 3 5 5 4 1 5 0 1 1 0 5 3 0 5 1 1 1 1]\n",
            "y_val [5 4 5 1 0 5 1 3 3 5 1 2 1 1 0 1 1 3 5 5 5 1 4 4 1 4 5 1 4 1 0 4 0 0 0 5 5\n",
            " 4 1 1 2 0 1 3 4 4 1 1 3 5 3 5 5 4 1 5 0 1 1 0 5 3 0 5 1 1 1 1]\n",
            "y_pred before save =  \n",
            " [[7.95762971e-05 5.03611300e-05 2.13929798e-06 6.71480439e-06\n",
            "  5.02706314e-07 9.99860644e-01]\n",
            " [1.81767391e-05 1.09278437e-06 3.71465212e-05 1.97956790e-04\n",
            "  9.99339521e-01 4.06071922e-04]\n",
            " [1.50127767e-06 1.37123493e-06 2.17202558e-08 8.47481516e-08\n",
            "  5.21007770e-09 9.99997020e-01]\n",
            " [1.97084509e-02 9.79649901e-01 3.54018084e-07 4.35659080e-04\n",
            "  9.01695148e-06 1.96663706e-04]\n",
            " [9.99831557e-01 1.57588816e-04 3.05831982e-08 7.03838964e-07\n",
            "  4.28620240e-07 9.66178413e-06]\n",
            " [4.93617972e-06 1.19782271e-04 7.48225193e-06 1.38098699e-06\n",
            "  3.81760447e-06 9.99862552e-01]\n",
            " [3.27238231e-05 9.96527731e-01 4.03746162e-06 9.20210150e-05\n",
            "  3.20943794e-03 1.34004760e-04]\n",
            " [4.97181736e-06 1.42860217e-05 3.17284648e-05 9.99205053e-01\n",
            "  7.40074494e-04 3.88032095e-06]\n",
            " [5.14226413e-05 5.59092030e-07 7.72366491e-07 9.99797881e-01\n",
            "  1.40372358e-04 8.92782282e-06]\n",
            " [9.43460464e-07 2.68456515e-05 2.97296424e-06 1.77506763e-07\n",
            "  3.74504992e-07 9.99968648e-01]\n",
            " [4.29606825e-06 9.84592855e-01 1.36455469e-07 1.77650406e-06\n",
            "  1.53858988e-02 1.50589676e-05]\n",
            " [1.70284438e-05 5.05495071e-01 4.94487226e-01 3.95729501e-07\n",
            "  9.86766935e-09 1.83777871e-07]\n",
            " [1.12418718e-07 9.99998331e-01 1.57883817e-09 2.27959873e-08\n",
            "  4.44488961e-07 1.09063967e-06]\n",
            " [3.47351055e-08 9.99999285e-01 2.68696027e-07 2.79159501e-10\n",
            "  4.15994073e-10 4.99190321e-07]\n",
            " [9.99984145e-01 5.15523607e-06 7.05315557e-08 9.86622268e-08\n",
            "  7.25015616e-06 3.22073674e-06]\n",
            " [6.75298566e-07 9.99988437e-01 2.41915608e-08 2.31533846e-07\n",
            "  6.55885560e-06 4.03453259e-06]\n",
            " [4.21645818e-05 6.55909025e-05 1.09688990e-05 6.78663564e-05\n",
            "  9.99800503e-01 1.29089149e-05]\n",
            " [5.31655701e-07 1.23767450e-03 2.56913281e-05 9.98568416e-01\n",
            "  1.67286446e-04 3.56071212e-07]\n",
            " [3.40264896e-03 2.16251798e-03 9.67590381e-07 7.16683985e-07\n",
            "  1.12425028e-07 9.94432986e-01]\n",
            " [2.50961002e-05 4.87677287e-04 1.83591401e-05 1.45801596e-05\n",
            "  1.47463288e-05 9.99439538e-01]\n",
            " [6.63956007e-06 9.08300790e-05 9.93467620e-06 2.61650371e-06\n",
            "  3.89310253e-06 9.99886036e-01]\n",
            " [1.12212479e-01 8.87743711e-01 7.70599307e-10 4.69661705e-11\n",
            "  1.00319648e-10 4.38204843e-05]\n",
            " [1.60437576e-05 5.33379080e-07 2.47590779e-05 1.60463518e-04\n",
            "  9.99393702e-01 4.04496066e-04]\n",
            " [4.70593746e-04 7.71430787e-04 5.41658846e-05 3.56509030e-04\n",
            "  9.98191893e-01 1.55370959e-04]\n",
            " [7.48531079e-07 9.99983788e-01 2.56167332e-09 2.37221954e-07\n",
            "  1.40021584e-05 1.27665021e-06]\n",
            " [3.50931950e-05 4.02776413e-06 6.23189771e-05 7.75289664e-05\n",
            "  9.99288917e-01 5.32075705e-04]\n",
            " [1.81182531e-05 7.52680353e-06 1.04017490e-05 6.44119700e-06\n",
            "  1.00600819e-05 9.99947429e-01]\n",
            " [1.77952697e-05 9.93014932e-01 1.13890652e-04 2.66443414e-04\n",
            "  5.73035190e-03 8.56546452e-04]\n",
            " [7.79579277e-05 1.70678049e-05 1.04984210e-04 1.97866466e-04\n",
            "  9.98746395e-01 8.55673396e-04]\n",
            " [5.24195784e-04 9.99436796e-01 3.30550647e-05 4.16441117e-06\n",
            "  3.16565348e-07 1.47999742e-06]\n",
            " [3.59193873e-05 1.63994508e-03 2.44001567e-04 9.97099876e-01\n",
            "  9.77175543e-04 3.13309238e-06]\n",
            " [4.13477719e-05 1.12943808e-05 8.37935077e-05 2.35415442e-04\n",
            "  9.99062598e-01 5.65539405e-04]\n",
            " [9.98845577e-01 1.07660005e-03 1.45639297e-06 8.51791447e-06\n",
            "  3.66037852e-07 6.73989271e-05]\n",
            " [9.99901414e-01 8.91065938e-05 1.95205132e-08 5.11537507e-07\n",
            "  2.34107938e-06 6.59802708e-06]\n",
            " [9.99813020e-01 1.85251731e-04 3.03654737e-08 1.70207284e-06\n",
            "  2.60473350e-08 7.20049229e-08]\n",
            " [1.33473305e-02 4.34802612e-03 7.01399529e-07 3.53960871e-07\n",
            "  7.27789669e-08 9.82303560e-01]\n",
            " [1.72637137e-05 5.07844197e-06 7.71492978e-06 5.01961222e-06\n",
            "  6.84025918e-06 9.99958038e-01]\n",
            " [2.56167677e-05 2.33557512e-06 4.89283120e-05 7.65256264e-05\n",
            "  9.99399662e-01 4.46873892e-04]\n",
            " [2.32685998e-05 9.56475019e-01 6.20402163e-04 1.27264345e-03\n",
            "  4.07230146e-02 8.85620713e-04]\n",
            " [4.67110385e-06 9.99811590e-01 4.88488396e-08 5.66121207e-06\n",
            "  1.48004983e-04 3.01222499e-05]\n",
            " [3.77780452e-07 2.03779005e-02 9.79621768e-01 2.18199880e-09\n",
            "  1.71319237e-10 1.00280477e-08]\n",
            " [9.93695915e-01 1.00980536e-03 5.12116458e-07 5.19296713e-03\n",
            "  9.61505939e-05 4.60477349e-06]\n",
            " [4.11671208e-05 9.99895215e-01 9.66053015e-09 4.50260723e-06\n",
            "  5.33211787e-05 5.84346844e-06]\n",
            " [3.61942867e-08 1.76537083e-04 3.61642014e-06 9.99792635e-01\n",
            "  2.71654008e-05 3.29773435e-08]\n",
            " [3.95616553e-05 7.13349255e-06 6.09073722e-05 2.15451757e-04\n",
            "  9.99136746e-01 5.40299690e-04]\n",
            " [2.49614350e-05 1.88943034e-06 4.13878079e-05 5.22551127e-05\n",
            "  9.99441564e-01 4.38006828e-04]\n",
            " [1.46655420e-05 9.93048012e-01 8.53742094e-05 1.13133888e-03\n",
            "  5.28738834e-03 4.33326437e-04]\n",
            " [3.86516418e-04 9.62069154e-01 2.10136801e-04 8.32017977e-03\n",
            "  2.85295583e-02 4.84546414e-04]\n",
            " [2.88615496e-08 6.76208525e-04 1.65183941e-04 9.98955607e-01\n",
            "  2.02803363e-04 1.10935993e-07]\n",
            " [3.63731488e-06 2.69781822e-06 4.14907390e-06 5.30704256e-07\n",
            "  4.72329111e-06 9.99984264e-01]\n",
            " [1.53665133e-06 8.11726146e-04 2.60613251e-05 9.98889863e-01\n",
            "  2.69974815e-04 8.07908577e-07]\n",
            " [1.93230298e-04 1.83584270e-05 1.30214248e-05 2.39380115e-05\n",
            "  6.70444115e-06 9.99744713e-01]\n",
            " [3.54789881e-06 3.16716942e-05 7.41937674e-06 9.70385599e-07\n",
            "  2.87505645e-06 9.99953508e-01]\n",
            " [4.64465802e-06 3.00571672e-04 9.20491232e-07 2.90550645e-07\n",
            "  9.99691963e-01 1.63949824e-06]\n",
            " [5.01663271e-05 9.99245882e-01 1.36836292e-07 6.96737610e-04\n",
            "  4.18467522e-07 6.68540542e-06]\n",
            " [5.71741257e-05 1.91939216e-05 1.33592857e-05 9.88585725e-06\n",
            "  2.26448742e-06 9.99898076e-01]\n",
            " [9.99867439e-01 1.15173505e-04 3.44764928e-08 8.03979276e-07\n",
            "  7.32653007e-07 1.58664334e-05]\n",
            " [1.11043039e-06 9.99860764e-01 5.60186782e-05 4.16561525e-05\n",
            "  1.59645822e-06 3.89166307e-05]\n",
            " [6.05332730e-07 9.99998212e-01 3.64643910e-07 6.79861500e-07\n",
            "  2.40515625e-08 1.48148899e-07]\n",
            " [9.99482393e-01 5.01740607e-04 6.57414034e-07 1.48658701e-05\n",
            "  7.38125934e-08 1.11500135e-07]\n",
            " [2.06468685e-05 1.38742562e-05 4.00133013e-06 7.29307840e-06\n",
            "  9.79870720e-07 9.99953151e-01]\n",
            " [4.15796997e-08 1.77364767e-04 4.35263755e-05 9.99646544e-01\n",
            "  1.32393761e-04 1.00729309e-07]\n",
            " [9.99899268e-01 9.02267711e-05 3.57606673e-08 6.73063369e-07\n",
            "  4.08255744e-07 9.37502955e-06]\n",
            " [8.25587813e-06 6.88385990e-05 2.29830275e-05 4.18687108e-07\n",
            "  6.15339843e-07 9.99898911e-01]\n",
            " [4.94802208e-08 9.99992967e-01 6.76789341e-06 8.81052870e-12\n",
            "  3.33618827e-11 2.83545631e-07]\n",
            " [2.00179571e-08 9.99996901e-01 2.16539561e-07 3.00068359e-10\n",
            "  1.17646437e-09 2.86596082e-06]\n",
            " [4.34620188e-06 9.99738991e-01 2.48136988e-04 7.70729400e-07\n",
            "  4.98102040e-08 7.83024552e-06]\n",
            " [3.42343327e-07 9.99997497e-01 2.64195865e-08 1.47742654e-08\n",
            "  1.39267172e-07 2.06863660e-06]]\n",
            "Histórico\n",
            "      accuracy  false_negatives  false_positives      loss  precision  \\\n",
            "0     0.431373            162.0             17.0  1.408498   0.711864   \n",
            "1     0.794118             75.0             20.0  0.618916   0.865772   \n",
            "2     0.808824             45.0             28.0  0.493600   0.850267   \n",
            "3     0.838235             46.0             20.0  0.446913   0.887640   \n",
            "4     0.769608             50.0             36.0  0.463436   0.810526   \n",
            "...        ...              ...              ...       ...        ...   \n",
            "1495  1.000000              0.0              0.0  0.001847   1.000000   \n",
            "1496  1.000000              0.0              0.0  0.002981   1.000000   \n",
            "1497  1.000000              0.0              0.0  0.002361   1.000000   \n",
            "1498  1.000000              0.0              0.0  0.002397   1.000000   \n",
            "1499  1.000000              0.0              0.0  0.002974   1.000000   \n",
            "\n",
            "        recall  true_negatives  true_positives  learning_rate  \n",
            "0     0.205882          1003.0            42.0         0.0010  \n",
            "1     0.632353          1000.0           129.0         0.0010  \n",
            "2     0.779412           992.0           159.0         0.0010  \n",
            "3     0.774510          1000.0           158.0         0.0010  \n",
            "4     0.754902           984.0           154.0         0.0010  \n",
            "...        ...             ...             ...            ...  \n",
            "1495  1.000000          1020.0           204.0         0.0001  \n",
            "1496  1.000000          1020.0           204.0         0.0001  \n",
            "1497  1.000000          1020.0           204.0         0.0001  \n",
            "1498  1.000000          1020.0           204.0         0.0001  \n",
            "1499  1.000000          1020.0           204.0         0.0001  \n",
            "\n",
            "[1500 rows x 9 columns]\n",
            "Temp: 0.9567687747035573\n",
            "   precision  accuracy    recall  f1_score    duration  std  specificity\n",
            "0   0.956769  0.955882  0.892754  0.909379  363.970363  0.0      0.99069\n",
            "\t\t\t\tDONE\n"
          ]
        }
      ],
      "source": [
        "# run nb_iter_ iterations of Inception on the whole TSC archive\n",
        "classifier_name = 'inception'\n",
        "#archive_name = ARCHIVE_NAMES[0]\n",
        "archive_name = UNIVARIATE_ARCHIVE_NAMES[0]\n",
        "nb_iter_ = 10\n",
        "\n",
        "datasets_dict = read_all_datasets(root_dir, archive_name)\n",
        "\n",
        "for iter in range(nb_iter_):\n",
        "    print('\\t\\titer', iter)\n",
        "\n",
        "    trr = ''\n",
        "    if iter != 0:\n",
        "        trr = '_itr_' + str(iter)\n",
        "\n",
        "    tmp_output_directory = root_dir + '/results/' + classifier_name + '/' + archive_name + trr + '/'\n",
        "\n",
        "    for dataset_name in dataset_names_for_archive[archive_name]:\n",
        "        print('\\t\\t\\tdataset_name: ', dataset_name)\n",
        "\n",
        "        x_train, y_train, x_test, y_test, x_test, x_val, y_val, y_true, nb_classes, y_true_train, enc = prepare_data()\n",
        "        # print(f\"Valor de y_train: {y_train}\")\n",
        "        # print(f\"Valor de x_train: {x_train}\")\n",
        "\n",
        "\n",
        "        output_directory = tmp_output_directory + dataset_name + '/'\n",
        "        print(f\"output_directory: {output_directory}\")\n",
        "        temp_output_directory = create_directory(output_directory)\n",
        "\n",
        "        if temp_output_directory is None:\n",
        "            print('Already_done', tmp_output_directory, dataset_name)\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            with tf.device('/device:GPU:0'):\n",
        "                fit_classifier(iter)\n",
        "                print('\\t\\t\\t\\tDONE')\n",
        "        except:\n",
        "            fit_classifier(iter)\n",
        "            print('\\t\\t\\t\\tDONE')\n",
        "\n",
        "            # the creation of this directory means\n",
        "            create_directory(output_directory + '/DONE')\n",
        "\n",
        "std = np.std(accuracy)\n",
        "root_dir = '/content/drive/MyDrive/Colab Notebooks/Candidas'\n",
        "\n",
        "clf_name = 'inception'\n",
        "\n",
        "path = '/'\n",
        "\n",
        "def update_metrics(root_dir,path ,archive_name, dataset_name, std):\n",
        "    output_dir = root_dir + path + archive_name + '/' \\\n",
        "                            + dataset_name + '/' + 'df_metrics.csv'\n",
        "    #print(output_dir)\n",
        "    #print('j = ',j,'i = ',i)\n",
        "    if os.path.exists(output_dir):\n",
        "        df_metrics = pd.read_csv(output_dir)\n",
        "        df_metrics['std'] = std\n",
        "        df_metrics.to_csv(output_dir + 'df_metrics_val.csv', index=False)\n",
        "    return df_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORgKD2Y8n1W2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8e5ea9b-2f06-4bda-b1e6-1a2a3b34a12c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo lido: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC/AllCandidasBload/df_metrics_val.csv\n",
            "Arquivo lido: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_1/AllCandidasBload/df_metrics_val.csv\n",
            "Arquivo lido: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_2/AllCandidasBload/df_metrics_val.csv\n",
            "Arquivo lido: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_3/AllCandidasBload/df_metrics_val.csv\n",
            "Arquivo lido: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_4/AllCandidasBload/df_metrics_val.csv\n",
            "Arquivo lido: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_5/AllCandidasBload/df_metrics_val.csv\n",
            "Arquivo lido: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_6/AllCandidasBload/df_metrics_val.csv\n",
            "Arquivo lido: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_7/AllCandidasBload/df_metrics_val.csv\n",
            "Arquivo lido: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_8/AllCandidasBload/df_metrics_val.csv\n",
            "Arquivo lido: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_9/AllCandidasBload/df_metrics_val.csv\n",
            "  classifier_name archive_name      dataset_name  precision    recall  \\\n",
            "0       inception          TSC  AllCandidasBload   0.906944  0.939855   \n",
            "1       inception    TSC_itr_1  AllCandidasBload   0.934848  0.961594   \n",
            "2       inception    TSC_itr_2  AllCandidasBload   0.837729  0.743478   \n",
            "3       inception    TSC_itr_3  AllCandidasBload   0.964015  0.976087   \n",
            "4       inception    TSC_itr_4  AllCandidasBload   0.964015  0.976087   \n",
            "5       inception    TSC_itr_5  AllCandidasBload   0.888450  0.847101   \n",
            "6       inception    TSC_itr_6  AllCandidasBload   0.940705  0.961594   \n",
            "7       inception    TSC_itr_7  AllCandidasBload   0.947348  0.968841   \n",
            "8       inception    TSC_itr_8  AllCandidasBload   0.951389  0.968841   \n",
            "9       inception    TSC_itr_9  AllCandidasBload   0.956769  0.892754   \n",
            "\n",
            "   f1_score  accuracy  specificity    duration  std_f1_score  std_accuracy  \\\n",
            "0  0.913889  0.897059     0.980026  413.800327           0.0           0.0   \n",
            "1  0.942252  0.941176     0.988930  410.693612           0.0           0.0   \n",
            "2  0.713300  0.691176     0.941510  384.549992           0.0           0.0   \n",
            "3  0.968477  0.970588     0.994394  393.440416           0.0           0.0   \n",
            "4  0.968477  0.970588     0.994394  372.577648           0.0           0.0   \n",
            "5  0.843442  0.882353     0.976888  373.402907           0.0           0.0   \n",
            "6  0.946750  0.941176     0.988647  375.191960           0.0           0.0   \n",
            "7  0.956710  0.955882     0.991521  367.028566           0.0           0.0   \n",
            "8  0.957390  0.955882     0.991521  372.721217           0.0           0.0   \n",
            "9  0.909379  0.955882     0.990690  363.970363           0.0           0.0   \n",
            "\n",
            "   std_specificity  ord1  ord2  iteration  \n",
            "0              0.0     0     0          0  \n",
            "1              0.0     0     1          1  \n",
            "2              0.0     0     2          2  \n",
            "3              0.0     0     3          3  \n",
            "4              0.0     0     4          4  \n",
            "5              0.0     0     5          5  \n",
            "6              0.0     0     6          6  \n",
            "7              0.0     0     7          7  \n",
            "8              0.0     0     8          8  \n",
            "9              0.0     0     9          9  \n",
            "Arquivo salvo em: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/inception.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Função auxiliar para criar o caminho\n",
        "def construct_path(*args):\n",
        "    return os.path.join(*args)\n",
        "\n",
        "# Função auxiliar para processar métricas de um dataset\n",
        "def process_dataset(clf_name, archive_name, dataset_name, root_dir, path):\n",
        "    # Construção do caminho do arquivo\n",
        "    output_dir = construct_path(root_dir, archive_name, dataset_name, 'df_metrics_val.csv')\n",
        "    # Verifica se o caminho existe\n",
        "    if not os.path.exists(output_dir):\n",
        "        print(f\"Caminho {output_dir} não encontrado. Pulando...\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Lê os dados\n",
        "        df_metrics = pd.read_csv(output_dir)\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao ler {output_dir}: {e}\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Arquivo lido: {output_dir}\")\n",
        "\n",
        "    # Coleta as métricas\n",
        "    return {\n",
        "        'classifier_name': clf_name,\n",
        "        'archive_name': archive_name,\n",
        "        'dataset_name': dataset_name,\n",
        "        'precision': df_metrics['precision'].mean(),\n",
        "        'recall': df_metrics['recall'].mean(),\n",
        "        'f1_score': df_metrics['f1_score'].mean(),\n",
        "        'accuracy': df_metrics['accuracy'].mean(),\n",
        "        'specificity': df_metrics['specificity'].mean(),\n",
        "        'duration': df_metrics['duration'].mean(),\n",
        "        'std_f1_score': np.std(df_metrics['f1_score']),\n",
        "        'std_accuracy': np.std(df_metrics['accuracy']),\n",
        "        'std_specificity': np.std(df_metrics['specificity']),\n",
        "    }\n",
        "\n",
        "# Função principal para gerar o CSV\n",
        "def gen_results_csv(clf_name, path, root_dir):\n",
        "    # Nomes das pastas e datasets\n",
        "    ARCHIVE_NAMES = [\n",
        "        'TSC', 'TSC_itr_1', 'TSC_itr_2', 'TSC_itr_3', 'TSC_itr_4',\n",
        "        'TSC_itr_5', 'TSC_itr_6', 'TSC_itr_7', 'TSC_itr_8', 'TSC_itr_9'\n",
        "    ]\n",
        "    # UNIVARIATE_DATASET_NAMES = ['AllCandidasBloadOversample']\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Iteração sobre os arquivos e datasets\n",
        "    for archive_index, archive_name in enumerate(ARCHIVE_NAMES):\n",
        "        for dataset_index, dataset_name in enumerate(UNIVARIATE_DATASET_NAMES):\n",
        "            result = process_dataset(clf_name, archive_name, dataset_name, root_dir, path)\n",
        "            if result:\n",
        "                result.update({\n",
        "                    'ord1': dataset_index,\n",
        "                    'ord2': archive_index,\n",
        "                    'iteration': archive_index,\n",
        "                })\n",
        "                results.append(result)\n",
        "\n",
        "    # Cria o DataFrame final\n",
        "    res_df = pd.DataFrame(results)\n",
        "\n",
        "    # Ordena o DataFrame\n",
        "    res_df = res_df.sort_values(by=['ord2', 'ord1']).reset_index(drop=True)\n",
        "\n",
        "    return res_df\n",
        "\n",
        "# Configuração dos parâmetros\n",
        "root_dir = '/content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/'\n",
        "clf_name = 'inception'\n",
        "path = '/'\n",
        "\n",
        "# Geração do CSV\n",
        "res = gen_results_csv(clf_name, path, root_dir)\n",
        "print(res)\n",
        "\n",
        "# Salvando o resultado em um arquivo CSV\n",
        "output_file = construct_path(root_dir, f\"{clf_name}.csv\")\n",
        "res.to_csv(output_file, index=False)\n",
        "print(f\"Arquivo salvo em: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMg9frP2Cp5Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc8ac54a-3c53-45fc-b659-b817354b0a18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo lido: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC/AllCandidasBload/all_class_metrics.csv\n",
            "Arquivo lido: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_1/AllCandidasBload/all_class_metrics.csv\n",
            "Arquivo lido: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_2/AllCandidasBload/all_class_metrics.csv\n",
            "Arquivo lido: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_3/AllCandidasBload/all_class_metrics.csv\n",
            "Arquivo lido: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_4/AllCandidasBload/all_class_metrics.csv\n",
            "Arquivo lido: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_5/AllCandidasBload/all_class_metrics.csv\n",
            "Arquivo lido: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_6/AllCandidasBload/all_class_metrics.csv\n",
            "Arquivo lido: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_7/AllCandidasBload/all_class_metrics.csv\n",
            "Arquivo lido: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_8/AllCandidasBload/all_class_metrics.csv\n",
            "Arquivo lido: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_9/AllCandidasBload/all_class_metrics.csv\n",
            "    class  accuracy  precision    recall  f1_score  specificity  fold  \\\n",
            "0       0  0.970588   0.900000  0.900000  0.900000     0.982759   0.0   \n",
            "1       1  0.911765   1.000000  0.739130  0.850000     1.000000   0.0   \n",
            "2       2  1.000000   1.000000  1.000000  1.000000     1.000000   0.0   \n",
            "3       3  0.985294   0.875000  1.000000  0.933333     0.983607   0.0   \n",
            "4       4  0.926471   0.666667  1.000000  0.800000     0.913793   0.0   \n",
            "5       5  1.000000   1.000000  1.000000  1.000000     1.000000   0.0   \n",
            "6       0  0.985294   1.000000  0.900000  0.947368     1.000000   1.0   \n",
            "7       1  0.955882   1.000000  0.869565  0.930233     1.000000   1.0   \n",
            "8       2  1.000000   1.000000  1.000000  1.000000     1.000000   1.0   \n",
            "9       3  0.955882   0.700000  1.000000  0.823529     0.950820   1.0   \n",
            "10      4  0.985294   0.909091  1.000000  0.952381     0.982759   1.0   \n",
            "11      5  1.000000   1.000000  1.000000  1.000000     1.000000   1.0   \n",
            "12      0  0.970588   0.900000  0.900000  0.900000     0.982759   2.0   \n",
            "13      1  0.735294   0.857143  0.260870  0.400000     0.977778   2.0   \n",
            "14      2  0.985294   1.000000  0.500000  0.666667     1.000000   2.0   \n",
            "15      3  0.720588   0.269231  1.000000  0.424242     0.688525   2.0   \n",
            "16      4  0.970588   1.000000  0.800000  0.888889     1.000000   2.0   \n",
            "17      5  1.000000   1.000000  1.000000  1.000000     1.000000   2.0   \n",
            "18      0  0.985294   1.000000  0.900000  0.947368     1.000000   3.0   \n",
            "19      1  0.985294   1.000000  0.956522  0.977778     1.000000   3.0   \n",
            "20      2  1.000000   1.000000  1.000000  1.000000     1.000000   3.0   \n",
            "21      3  0.985294   0.875000  1.000000  0.933333     0.983607   3.0   \n",
            "22      4  0.985294   0.909091  1.000000  0.952381     0.982759   3.0   \n",
            "23      5  1.000000   1.000000  1.000000  1.000000     1.000000   3.0   \n",
            "24      0  0.985294   1.000000  0.900000  0.947368     1.000000   4.0   \n",
            "25      1  0.985294   1.000000  0.956522  0.977778     1.000000   4.0   \n",
            "26      2  1.000000   1.000000  1.000000  1.000000     1.000000   4.0   \n",
            "27      3  0.985294   0.875000  1.000000  0.933333     0.983607   4.0   \n",
            "28      4  0.985294   0.909091  1.000000  0.952381     0.982759   4.0   \n",
            "29      5  1.000000   1.000000  1.000000  1.000000     1.000000   4.0   \n",
            "30      0  0.970588   0.900000  0.900000  0.900000     0.982759   5.0   \n",
            "31      1  0.911765   0.947368  0.782609  0.857143     0.977778   5.0   \n",
            "32      2  0.985294   1.000000  0.500000  0.666667     1.000000   5.0   \n",
            "33      3  0.926471   0.583333  1.000000  0.736842     0.918033   5.0   \n",
            "34      4  0.970588   0.900000  0.900000  0.900000     0.982759   5.0   \n",
            "35      5  1.000000   1.000000  1.000000  1.000000     1.000000   5.0   \n",
            "36      0  0.985294   1.000000  0.900000  0.947368     1.000000   6.0   \n",
            "37      1  0.955882   1.000000  0.869565  0.930233     1.000000   6.0   \n",
            "38      2  1.000000   1.000000  1.000000  1.000000     1.000000   6.0   \n",
            "39      3  0.985294   0.875000  1.000000  0.933333     0.983607   6.0   \n",
            "40      4  0.955882   0.769231  1.000000  0.869565     0.948276   6.0   \n",
            "41      5  1.000000   1.000000  1.000000  1.000000     1.000000   6.0   \n",
            "42      0  0.970588   0.900000  0.900000  0.900000     0.982759   7.0   \n",
            "43      1  0.970588   1.000000  0.913043  0.954545     1.000000   7.0   \n",
            "44      2  1.000000   1.000000  1.000000  1.000000     1.000000   7.0   \n",
            "45      3  0.985294   0.875000  1.000000  0.933333     0.983607   7.0   \n",
            "46      4  0.985294   0.909091  1.000000  0.952381     0.982759   7.0   \n",
            "47      5  1.000000   1.000000  1.000000  1.000000     1.000000   7.0   \n",
            "48      0  0.985294   1.000000  0.900000  0.947368     1.000000   8.0   \n",
            "49      1  0.970588   1.000000  0.913043  0.954545     1.000000   8.0   \n",
            "50      2  1.000000   1.000000  1.000000  1.000000     1.000000   8.0   \n",
            "51      3  0.985294   0.875000  1.000000  0.933333     0.983607   8.0   \n",
            "52      4  0.970588   0.833333  1.000000  0.909091     0.965517   8.0   \n",
            "53      5  1.000000   1.000000  1.000000  1.000000     1.000000   8.0   \n",
            "54      0  0.985294   1.000000  0.900000  0.947368     1.000000   9.0   \n",
            "55      1  0.970588   0.956522  0.956522  0.956522     0.977778   9.0   \n",
            "56      2  0.985294   1.000000  0.500000  0.666667     1.000000   9.0   \n",
            "57      3  0.985294   0.875000  1.000000  0.933333     0.983607   9.0   \n",
            "58      4  0.985294   0.909091  1.000000  0.952381     0.982759   9.0   \n",
            "59      5  1.000000   1.000000  1.000000  1.000000     1.000000   9.0   \n",
            "\n",
            "   archive_name      dataset_name classifier_name  \n",
            "0           TSC  AllCandidasBload       inception  \n",
            "1           TSC  AllCandidasBload       inception  \n",
            "2           TSC  AllCandidasBload       inception  \n",
            "3           TSC  AllCandidasBload       inception  \n",
            "4           TSC  AllCandidasBload       inception  \n",
            "5           TSC  AllCandidasBload       inception  \n",
            "6     TSC_itr_1  AllCandidasBload       inception  \n",
            "7     TSC_itr_1  AllCandidasBload       inception  \n",
            "8     TSC_itr_1  AllCandidasBload       inception  \n",
            "9     TSC_itr_1  AllCandidasBload       inception  \n",
            "10    TSC_itr_1  AllCandidasBload       inception  \n",
            "11    TSC_itr_1  AllCandidasBload       inception  \n",
            "12    TSC_itr_2  AllCandidasBload       inception  \n",
            "13    TSC_itr_2  AllCandidasBload       inception  \n",
            "14    TSC_itr_2  AllCandidasBload       inception  \n",
            "15    TSC_itr_2  AllCandidasBload       inception  \n",
            "16    TSC_itr_2  AllCandidasBload       inception  \n",
            "17    TSC_itr_2  AllCandidasBload       inception  \n",
            "18    TSC_itr_3  AllCandidasBload       inception  \n",
            "19    TSC_itr_3  AllCandidasBload       inception  \n",
            "20    TSC_itr_3  AllCandidasBload       inception  \n",
            "21    TSC_itr_3  AllCandidasBload       inception  \n",
            "22    TSC_itr_3  AllCandidasBload       inception  \n",
            "23    TSC_itr_3  AllCandidasBload       inception  \n",
            "24    TSC_itr_4  AllCandidasBload       inception  \n",
            "25    TSC_itr_4  AllCandidasBload       inception  \n",
            "26    TSC_itr_4  AllCandidasBload       inception  \n",
            "27    TSC_itr_4  AllCandidasBload       inception  \n",
            "28    TSC_itr_4  AllCandidasBload       inception  \n",
            "29    TSC_itr_4  AllCandidasBload       inception  \n",
            "30    TSC_itr_5  AllCandidasBload       inception  \n",
            "31    TSC_itr_5  AllCandidasBload       inception  \n",
            "32    TSC_itr_5  AllCandidasBload       inception  \n",
            "33    TSC_itr_5  AllCandidasBload       inception  \n",
            "34    TSC_itr_5  AllCandidasBload       inception  \n",
            "35    TSC_itr_5  AllCandidasBload       inception  \n",
            "36    TSC_itr_6  AllCandidasBload       inception  \n",
            "37    TSC_itr_6  AllCandidasBload       inception  \n",
            "38    TSC_itr_6  AllCandidasBload       inception  \n",
            "39    TSC_itr_6  AllCandidasBload       inception  \n",
            "40    TSC_itr_6  AllCandidasBload       inception  \n",
            "41    TSC_itr_6  AllCandidasBload       inception  \n",
            "42    TSC_itr_7  AllCandidasBload       inception  \n",
            "43    TSC_itr_7  AllCandidasBload       inception  \n",
            "44    TSC_itr_7  AllCandidasBload       inception  \n",
            "45    TSC_itr_7  AllCandidasBload       inception  \n",
            "46    TSC_itr_7  AllCandidasBload       inception  \n",
            "47    TSC_itr_7  AllCandidasBload       inception  \n",
            "48    TSC_itr_8  AllCandidasBload       inception  \n",
            "49    TSC_itr_8  AllCandidasBload       inception  \n",
            "50    TSC_itr_8  AllCandidasBload       inception  \n",
            "51    TSC_itr_8  AllCandidasBload       inception  \n",
            "52    TSC_itr_8  AllCandidasBload       inception  \n",
            "53    TSC_itr_8  AllCandidasBload       inception  \n",
            "54    TSC_itr_9  AllCandidasBload       inception  \n",
            "55    TSC_itr_9  AllCandidasBload       inception  \n",
            "56    TSC_itr_9  AllCandidasBload       inception  \n",
            "57    TSC_itr_9  AllCandidasBload       inception  \n",
            "58    TSC_itr_9  AllCandidasBload       inception  \n",
            "59    TSC_itr_9  AllCandidasBload       inception  \n",
            "Arquivo salvo em: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/inception_aggregated_metrics.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Função auxiliar para criar o caminho\n",
        "def construct_path(*args):\n",
        "    return os.path.join(*args)\n",
        "\n",
        "# Função auxiliar para processar métricas de um dataset\n",
        "def process_dataset(clf_name, archive_name, dataset_name, root_dir):\n",
        "    # Construção do caminho do arquivo\n",
        "    output_dir = construct_path(root_dir, archive_name, dataset_name, 'all_class_metrics.csv')\n",
        "\n",
        "    # Verifica se o caminho existe\n",
        "    if not os.path.exists(output_dir):\n",
        "        print(f\"Caminho {output_dir} não encontrado. Pulando...\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Lê os dados\n",
        "        df_metrics = pd.read_csv(output_dir)\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao ler {output_dir}: {e}\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Arquivo lido: {output_dir}\")\n",
        "\n",
        "    # Calcula a média das métricas por classe entre os folds\n",
        "    grouped_metrics = df_metrics.groupby('class').mean(numeric_only=True).reset_index()\n",
        "\n",
        "    # Adiciona informações adicionais (se necessário)\n",
        "    grouped_metrics['archive_name'] = archive_name\n",
        "    grouped_metrics['dataset_name'] = dataset_name\n",
        "    grouped_metrics['classifier_name'] = clf_name\n",
        "\n",
        "    return grouped_metrics\n",
        "\n",
        "# Função principal para gerar o CSV consolidado\n",
        "def gen_results_csv(clf_name, root_dir):\n",
        "    # Nomes das pastas e datasets\n",
        "    ARCHIVE_NAMES = [\n",
        "        'TSC', 'TSC_itr_1', 'TSC_itr_2', 'TSC_itr_3', 'TSC_itr_4',\n",
        "        'TSC_itr_5', 'TSC_itr_6', 'TSC_itr_7', 'TSC_itr_8', 'TSC_itr_9'\n",
        "    ]\n",
        "    # DATASET_NAME = ['AllCandidasBloadOversample']\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Iteração sobre os arquivos e datasets\n",
        "    for archive_name in ARCHIVE_NAMES:\n",
        "        for dataset_name in UNIVARIATE_DATASET_NAMES:\n",
        "            result = process_dataset(clf_name, archive_name, dataset_name, root_dir)\n",
        "            if result is not None:\n",
        "                results.append(result)\n",
        "\n",
        "    # Concatena todos os resultados em um único DataFrame\n",
        "    if results:\n",
        "        final_df = pd.concat(results, ignore_index=True)\n",
        "    else:\n",
        "        final_df = pd.DataFrame()  # Retorna DataFrame vazio caso não haja dados\n",
        "\n",
        "    return final_df\n",
        "\n",
        "# Configuração dos parâmetros\n",
        "root_dir = '/content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/'\n",
        "clf_name = 'inception'\n",
        "\n",
        "# Geração do CSV consolidado\n",
        "res = gen_results_csv(clf_name, root_dir)\n",
        "if not res.empty:\n",
        "    print(res)\n",
        "\n",
        "    # Salvando o resultado em um arquivo CSV\n",
        "    output_file = construct_path(root_dir, f\"{clf_name}_aggregated_metrics.csv\")\n",
        "    res.to_csv(output_file, index=False)\n",
        "    print(f\"Arquivo salvo em: {output_file}\")\n",
        "else:\n",
        "    print(\"Nenhum dado encontrado para processar.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSYl8Z5BJJmz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f17e381-c26f-4602-acfc-6e64e03002e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Arquivo lido com sucesso: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC/AllCandidasBload/all_class_metrics.csv\n",
            "[INFO] Arquivo lido com sucesso: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_1/AllCandidasBload/all_class_metrics.csv\n",
            "[INFO] Arquivo lido com sucesso: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_2/AllCandidasBload/all_class_metrics.csv\n",
            "[INFO] Arquivo lido com sucesso: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_3/AllCandidasBload/all_class_metrics.csv\n",
            "[INFO] Arquivo lido com sucesso: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_4/AllCandidasBload/all_class_metrics.csv\n",
            "[INFO] Arquivo lido com sucesso: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_5/AllCandidasBload/all_class_metrics.csv\n",
            "[INFO] Arquivo lido com sucesso: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_6/AllCandidasBload/all_class_metrics.csv\n",
            "[INFO] Arquivo lido com sucesso: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_7/AllCandidasBload/all_class_metrics.csv\n",
            "[INFO] Arquivo lido com sucesso: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_8/AllCandidasBload/all_class_metrics.csv\n",
            "[INFO] Arquivo lido com sucesso: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/TSC_itr_9/AllCandidasBload/all_class_metrics.csv\n",
            "[SUCESSO] Arquivo salvo em: /content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/inception_class_average_metrics.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def construct_path(*args):\n",
        "    \"\"\"\n",
        "    Constrói um caminho usando `os.path.join`.\n",
        "    \"\"\"\n",
        "    return os.path.join(*args)\n",
        "\n",
        "\n",
        "def process_dataset(clf_name, archive_name, dataset_name, root_dir):\n",
        "    \"\"\"\n",
        "    Processa métricas de um dataset específico, coletando as métricas por classe.\n",
        "\n",
        "    Args:\n",
        "        clf_name (str): Nome do classificador.\n",
        "        archive_name (str): Nome do arquivo de métricas.\n",
        "        dataset_name (str): Nome do dataset.\n",
        "        root_dir (str): Diretório raiz dos resultados.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame | None: DataFrame com métricas por classe ou None se o arquivo não for encontrado.\n",
        "    \"\"\"\n",
        "    output_dir = construct_path(root_dir, archive_name, dataset_name, 'all_class_metrics.csv')\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        print(f\"[AVISO] Caminho {output_dir} não encontrado. Pulando...\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        df_metrics = pd.read_csv(output_dir)\n",
        "        print(f\"[INFO] Arquivo lido com sucesso: {output_dir}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[ERRO] Falha ao ler {output_dir}: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Retorna os dados, mantendo as informações de classe\n",
        "    df_metrics['archive_name'] = archive_name\n",
        "    df_metrics['dataset_name'] = dataset_name\n",
        "    df_metrics['classifier_name'] = clf_name\n",
        "\n",
        "    return df_metrics\n",
        "\n",
        "\n",
        "def gen_results_csv(clf_name, root_dir, archive_names=None, dataset_names=None):\n",
        "    \"\"\"\n",
        "    Consolida métricas de diferentes datasets, calcula médias por classe e gera um DataFrame final.\n",
        "\n",
        "    Args:\n",
        "        clf_name (str): Nome do classificador.\n",
        "        root_dir (str): Diretório raiz dos resultados.\n",
        "        archive_names (list | None): Lista de arquivos a serem processados.\n",
        "        dataset_names (list | None): Lista de datasets a serem processados.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame consolidado com métricas médias por classe.\n",
        "    \"\"\"\n",
        "    if archive_names is None:\n",
        "        archive_names = [\n",
        "            'TSC', 'TSC_itr_1', 'TSC_itr_2', 'TSC_itr_3',\n",
        "            'TSC_itr_4', 'TSC_itr_5', 'TSC_itr_6', 'TSC_itr_7',\n",
        "            'TSC_itr_8', 'TSC_itr_9'\n",
        "        ]\n",
        "\n",
        "    # if dataset_names is None:\n",
        "    #     dataset_names = ['AllCandidasBloadOversample']\n",
        "    # if UNIVARIATE_DATASET_NAMES is None:\n",
        "    #      UNIVARIATE_DATASET_NAMES = ['AllCandidasBload']\n",
        "    all_metrics = []\n",
        "    for archive_name in archive_names:\n",
        "        for dataset_name in UNIVARIATE_DATASET_NAMES:\n",
        "            result = process_dataset(clf_name, archive_name, dataset_name, root_dir)\n",
        "            if result is not None:\n",
        "                all_metrics.append(result)\n",
        "\n",
        "    # Concatena todos os dados em um único DataFrame\n",
        "    if all_metrics:\n",
        "        all_data = pd.concat(all_metrics, ignore_index=True)\n",
        "\n",
        "        # Calcula a média das métricas por classe\n",
        "        metrics_mean = (\n",
        "            all_data\n",
        "            .groupby('class')\n",
        "            .mean(numeric_only=True)\n",
        "            .reset_index()\n",
        "        )\n",
        "    else:\n",
        "        print(\"[AVISO] Nenhum dado encontrado para processar.\")\n",
        "        metrics_mean = pd.DataFrame()\n",
        "\n",
        "    return metrics_mean\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Configurações\n",
        "    ROOT_DIR = '/content/drive/MyDrive/Colab Notebooks/Candidas/results/inception/'\n",
        "    CLF_NAME = 'inception'\n",
        "\n",
        "    # Geração do CSV consolidado\n",
        "    metrics_by_class = gen_results_csv(CLF_NAME, ROOT_DIR)\n",
        "    if not metrics_by_class.empty:\n",
        "        # Salvando o resultado em um arquivo CSV\n",
        "        output_file = construct_path(ROOT_DIR, f\"{CLF_NAME}_class_average_metrics.csv\")\n",
        "        metrics_by_class.to_csv(output_file, index=False)\n",
        "        print(f\"[SUCESSO] Arquivo salvo em: {output_file}\")\n",
        "    else:\n",
        "        print(\"[ERRO] Nenhum resultado gerado.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oB8eGmJ2tQ1K"
      },
      "outputs": [],
      "source": [
        "from pickle import dump\n",
        "def save_results(df_to_save, name, train_val_test):\n",
        "    print(\"Saving metrics...\")\n",
        "    print(f\"Df accuracy: {df_to_save}\")\n",
        "    df_to_save.to_csv(root_dir+ '/df_'+name+'_'+train_val_test+'2.csv', index=False)\n",
        "    print(\"Accuracy of models:\")\n",
        "    print(df_to_save)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOJuNN0xtJYO"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import time\n",
        "def test_final_model(x_val, y_val, model):\n",
        "    scoring = ['accuracy','precision_macro', 'recall_macro','f1_macro']\n",
        "#     for name, model in models:\n",
        "        # df_test = cross_validate(model, X_test, y_test, cv=kf, scoring=scoring\n",
        "        #                          , return_train_score=True)\n",
        "#         print(f'Model in test: {name}')\n",
        "\n",
        "    df_test = pd.DataFrame([], columns=['accuracy','recall','precision','f1_score','specificity','testTime'])\n",
        "\n",
        "    start_time = time.time()\n",
        "    y_pred = model.predict(x_val, batch_size=1500)\n",
        "    time_prediction = time.time()-start_time\n",
        "\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    onehot_encoder = OneHotEncoder()\n",
        "    y_pred = y_pred.reshape(len(y_pred), 1)\n",
        "    y_pred = onehot_encoder.fit_transform(y_pred)\n",
        "    print(\"Y pred ---- \")\n",
        "    print(y_pred)\n",
        "    print(\"Y val\")\n",
        "    print(y_val)\n",
        "    accuracy  =  accuracy_score(y_val, y_pred)\n",
        "    recall    =  recall_score(y_val, y_pred, average='macro')\n",
        "    precision =  precision_score(y_val, y_pred, average='macro')\n",
        "    f1  =  f1_score(y_val, y_pred, average='macro')\n",
        "    specificity = specificity_score(y_val, y_pred)\n",
        "    print(f\"accuracy: {accuracy}, recall: {recall}, precision: {precision},f1: {f1} \")\n",
        "    df_test.at[0, 'accuracy'] = accuracy\n",
        "    df_test.at[0, 'recall'] = recall\n",
        "    df_test.at[0,'precision'] = precision\n",
        "    df_test.at[0,'f1_score'] = f1\n",
        "    df_test.at[0,'specificity'] = specificity\n",
        "    df_test.at[0,'testTime'] =  time_prediction\n",
        "    print(df_test.keys())\n",
        "    save_results(df_test,\"INCEPTION\", 'test')\n",
        "    print(\"Finished test!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SehDUvqF9Oie",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1484e24f-8e7e-4844-8ec5-61608bd7c85d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Candidas/results/inception//TSC_itr_3/\n"
          ]
        }
      ],
      "source": [
        "archive_name = 'TSC_itr_3'\n",
        "tmp_output_directory = root_dir + '/'+ archive_name + '/'\n",
        "output_directory = tmp_output_directory + dataset_name + '/'\n",
        "print(tmp_output_directory)\n",
        "# dataset = np.load(output_directory+'/y_pred'+'.npy', encoding='bytes')\n",
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVn0WmTtW9a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9588e9af-e08d-4b2e-9b27-22ee53831dc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(68, 512, 1)\n",
            "(68, 6)\n"
          ]
        }
      ],
      "source": [
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAtP3OMKY15H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dr485WvaZtNC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92e7205c-fa2e-4c78-b547-f72472363e4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "Y pred ---- \n",
            "  (0, 5)\t1.0\n",
            "  (1, 0)\t1.0\n",
            "  (2, 4)\t1.0\n",
            "  (3, 3)\t1.0\n",
            "  (4, 3)\t1.0\n",
            "  (5, 1)\t1.0\n",
            "  (6, 1)\t1.0\n",
            "  (7, 5)\t1.0\n",
            "  (8, 4)\t1.0\n",
            "  (9, 1)\t1.0\n",
            "  (10, 0)\t1.0\n",
            "  (11, 4)\t1.0\n",
            "  (12, 0)\t1.0\n",
            "  (13, 3)\t1.0\n",
            "  (14, 4)\t1.0\n",
            "  (15, 1)\t1.0\n",
            "  (16, 5)\t1.0\n",
            "  (17, 3)\t1.0\n",
            "  (18, 1)\t1.0\n",
            "  (19, 3)\t1.0\n",
            "  (20, 5)\t1.0\n",
            "  (21, 1)\t1.0\n",
            "  (22, 1)\t1.0\n",
            "  (23, 4)\t1.0\n",
            "  (24, 3)\t1.0\n",
            "  :\t:\n",
            "  (43, 3)\t1.0\n",
            "  (44, 5)\t1.0\n",
            "  (45, 3)\t1.0\n",
            "  (46, 4)\t1.0\n",
            "  (47, 3)\t1.0\n",
            "  (48, 3)\t1.0\n",
            "  (49, 1)\t1.0\n",
            "  (50, 1)\t1.0\n",
            "  (51, 1)\t1.0\n",
            "  (52, 3)\t1.0\n",
            "  (53, 5)\t1.0\n",
            "  (54, 5)\t1.0\n",
            "  (55, 1)\t1.0\n",
            "  (56, 1)\t1.0\n",
            "  (57, 5)\t1.0\n",
            "  (58, 0)\t1.0\n",
            "  (59, 0)\t1.0\n",
            "  (60, 1)\t1.0\n",
            "  (61, 1)\t1.0\n",
            "  (62, 4)\t1.0\n",
            "  (63, 5)\t1.0\n",
            "  (64, 2)\t1.0\n",
            "  (65, 3)\t1.0\n",
            "  (66, 5)\t1.0\n",
            "  (67, 3)\t1.0\n",
            "Y val\n",
            "[[0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]]\n",
            "accuracy: 0.9117647058823529, recall: 0.9315476190476191, precision: 0.9357142857142856,f1: 0.9279653950385658 \n",
            "Index(['accuracy', 'recall', 'precision', 'f1_score', 'specificity',\n",
            "       'testTime'],\n",
            "      dtype='object')\n",
            "Saving metrics...\n",
            "Df accuracy:    accuracy    recall precision  f1_score specificity  testTime\n",
            "0  0.911765  0.931548  0.935714  0.927965    0.981414  1.923338\n",
            "Accuracy of models:\n",
            "   accuracy    recall precision  f1_score specificity  testTime\n",
            "0  0.911765  0.931548  0.935714  0.927965    0.981414  1.923338\n",
            "Finished test!\n"
          ]
        }
      ],
      "source": [
        "model_path = output_directory + 'best_model.keras'\n",
        "model = keras.models.load_model(model_path)\n",
        "test_final_model(x_val, y_val, model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}